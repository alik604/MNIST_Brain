{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "MNIST_Brain.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5JzZOjTe8kRH",
        "nHCG13WezgxI",
        "Wrtn4ULykv6c",
        "EB0z70vE16Hr",
        "wECziwje8dvB",
        "OaH-aW_EzgxU",
        "q9UD7cFuzgxZ"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alik604/MNIST_Brain/blob/master/MNIST_Brain_colab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txc_ib9C4Eb0",
        "colab_type": "text"
      },
      "source": [
        "# NMIST Brain \n",
        "\n",
        "### - by Khizr Ali Pardhan [alik604](https://github.com/alik604/ReadMe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvuUqSU5axGC",
        "colab_type": "text"
      },
      "source": [
        "notes:\n",
        "\n",
        "* can use pad sequences to use all data, as it is not square\n",
        "* try HMM and other stats-type models \n",
        "* try bi direction LSTM or GRU\n",
        "* [LSTM/GRU - CNN (cov1D)](https://keras.io/examples/imdb_cnn_lstm/)\n",
        "* try the above with attensino \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmI36XdVzgv5",
        "colab_type": "code",
        "outputId": "d6d54ca3-b559-424d-8adf-4abf479cfc11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import * \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.constraints import max_norm\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JzZOjTe8kRH",
        "colab_type": "text"
      },
      "source": [
        "## Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMTpaCsIzgv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/alik604/MNIST_Brain/master/MW%20-%20Copy.csv'\n",
        "raw = pd.read_csv(url,low_memory=False,header= None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkMGtQ54zgwD",
        "colab_type": "text"
      },
      "source": [
        "FILE FORMAT:\n",
        "\n",
        "The data is stored in a very simple text format including:\n",
        "\n",
        "[id]: a numeric, only for reference purposes.\n",
        "\n",
        "[event] id, a integer, used to distinguish the same event captured at different brain locations, used only by multichannel devices (all except MW).\n",
        "\n",
        "[device]: a 2 character string, to identify the device used to capture the signals, \"MW\" for MindWave....\n",
        "\n",
        "[channel]: a string, to indentify the 10/20 brain location of the signal ....MindWave \"FP1\"\n",
        "\n",
        "[code]: a integer, to indentify the digit been thought/seen, with possible values 0,1,2,3,4,5,6,7,8,9 or -1 for random captured signals not related to any of the digits.\n",
        "\n",
        "[size]: a integer, to identify the size in number of values captured in the 2 seconds of this signal, since the Hz of each device varies, in \"theory\" the value is close to 512Hz for MW, 128Hz for EP, 220Hz for MU & 128Hz for IN, for each of the 2 seconds.\n",
        "\n",
        "[data]: a coma separated set of numbers, with the time-series amplitude of the signal, each device uses a different precision to identify the electrical potential captured from the brain: integers in the case of MW & MU or real numbers in the case of EP & IN.\n",
        "\n",
        "There is no headers in the files,  every line is  a signal, and the fields are separated by a tab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiCZFTaBzgwE",
        "colab_type": "code",
        "outputId": "a4c13533-b312-4b12-f684-1cb43317ffc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "raw.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>835</th>\n",
              "      <th>836</th>\n",
              "      <th>837</th>\n",
              "      <th>838</th>\n",
              "      <th>839</th>\n",
              "      <th>840</th>\n",
              "      <th>841</th>\n",
              "      <th>842</th>\n",
              "      <th>843</th>\n",
              "      <th>844</th>\n",
              "      <th>845</th>\n",
              "      <th>846</th>\n",
              "      <th>847</th>\n",
              "      <th>848</th>\n",
              "      <th>849</th>\n",
              "      <th>850</th>\n",
              "      <th>851</th>\n",
              "      <th>852</th>\n",
              "      <th>853</th>\n",
              "      <th>854</th>\n",
              "      <th>855</th>\n",
              "      <th>856</th>\n",
              "      <th>857</th>\n",
              "      <th>858</th>\n",
              "      <th>859</th>\n",
              "      <th>860</th>\n",
              "      <th>861</th>\n",
              "      <th>862</th>\n",
              "      <th>863</th>\n",
              "      <th>864</th>\n",
              "      <th>865</th>\n",
              "      <th>866</th>\n",
              "      <th>867</th>\n",
              "      <th>868</th>\n",
              "      <th>869</th>\n",
              "      <th>870</th>\n",
              "      <th>871</th>\n",
              "      <th>872</th>\n",
              "      <th>873</th>\n",
              "      <th>874</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25253\\t25253\\tMW\\tFP1\\t1\\t952\\t152</td>\n",
              "      <td>154</td>\n",
              "      <td>155</td>\n",
              "      <td>148</td>\n",
              "      <td>136</td>\n",
              "      <td>137</td>\n",
              "      <td>129</td>\n",
              "      <td>104</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>101</td>\n",
              "      <td>88</td>\n",
              "      <td>82</td>\n",
              "      <td>92</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>104</td>\n",
              "      <td>117</td>\n",
              "      <td>118</td>\n",
              "      <td>117</td>\n",
              "      <td>114</td>\n",
              "      <td>113</td>\n",
              "      <td>112</td>\n",
              "      <td>106</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>85</td>\n",
              "      <td>69</td>\n",
              "      <td>74</td>\n",
              "      <td>86</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "      <td>...</td>\n",
              "      <td>1098</td>\n",
              "      <td>1064</td>\n",
              "      <td>1030</td>\n",
              "      <td>995</td>\n",
              "      <td>960</td>\n",
              "      <td>925</td>\n",
              "      <td>896</td>\n",
              "      <td>865</td>\n",
              "      <td>833</td>\n",
              "      <td>803</td>\n",
              "      <td>773</td>\n",
              "      <td>745</td>\n",
              "      <td>721</td>\n",
              "      <td>696</td>\n",
              "      <td>674</td>\n",
              "      <td>650</td>\n",
              "      <td>629</td>\n",
              "      <td>608</td>\n",
              "      <td>585</td>\n",
              "      <td>564</td>\n",
              "      <td>544</td>\n",
              "      <td>524</td>\n",
              "      <td>506</td>\n",
              "      <td>488</td>\n",
              "      <td>470</td>\n",
              "      <td>453</td>\n",
              "      <td>438</td>\n",
              "      <td>423</td>\n",
              "      <td>404</td>\n",
              "      <td>373</td>\n",
              "      <td>323</td>\n",
              "      <td>249</td>\n",
              "      <td>156</td>\n",
              "      <td>48</td>\n",
              "      <td>-92</td>\n",
              "      <td>-302</td>\n",
              "      <td>-601</td>\n",
              "      <td>-901</td>\n",
              "      <td>-1157</td>\n",
              "      <td>-1364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4279\\t4279\\tMW\\tFP1\\t0\\t952\\t1261</td>\n",
              "      <td>1209</td>\n",
              "      <td>1158</td>\n",
              "      <td>1116</td>\n",
              "      <td>1090</td>\n",
              "      <td>1073</td>\n",
              "      <td>1059</td>\n",
              "      <td>1033</td>\n",
              "      <td>1003</td>\n",
              "      <td>967</td>\n",
              "      <td>930</td>\n",
              "      <td>892</td>\n",
              "      <td>845</td>\n",
              "      <td>789</td>\n",
              "      <td>762</td>\n",
              "      <td>778</td>\n",
              "      <td>773</td>\n",
              "      <td>721</td>\n",
              "      <td>660</td>\n",
              "      <td>617</td>\n",
              "      <td>589</td>\n",
              "      <td>568</td>\n",
              "      <td>539</td>\n",
              "      <td>507</td>\n",
              "      <td>487</td>\n",
              "      <td>486</td>\n",
              "      <td>485</td>\n",
              "      <td>482</td>\n",
              "      <td>469</td>\n",
              "      <td>441</td>\n",
              "      <td>409</td>\n",
              "      <td>371</td>\n",
              "      <td>324</td>\n",
              "      <td>274</td>\n",
              "      <td>237</td>\n",
              "      <td>219</td>\n",
              "      <td>199</td>\n",
              "      <td>183</td>\n",
              "      <td>166</td>\n",
              "      <td>138</td>\n",
              "      <td>...</td>\n",
              "      <td>-49</td>\n",
              "      <td>-55</td>\n",
              "      <td>-62</td>\n",
              "      <td>-61</td>\n",
              "      <td>-59</td>\n",
              "      <td>-67</td>\n",
              "      <td>-81</td>\n",
              "      <td>-90</td>\n",
              "      <td>-93</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-107</td>\n",
              "      <td>-120</td>\n",
              "      <td>-134</td>\n",
              "      <td>-149</td>\n",
              "      <td>-165</td>\n",
              "      <td>-177</td>\n",
              "      <td>-179</td>\n",
              "      <td>-181</td>\n",
              "      <td>-181</td>\n",
              "      <td>-174</td>\n",
              "      <td>-179</td>\n",
              "      <td>-195</td>\n",
              "      <td>-212</td>\n",
              "      <td>-237</td>\n",
              "      <td>-266</td>\n",
              "      <td>-280</td>\n",
              "      <td>-301</td>\n",
              "      <td>-339</td>\n",
              "      <td>-359</td>\n",
              "      <td>-363</td>\n",
              "      <td>-380</td>\n",
              "      <td>-419</td>\n",
              "      <td>-459</td>\n",
              "      <td>-488</td>\n",
              "      <td>-494</td>\n",
              "      <td>-513</td>\n",
              "      <td>-556</td>\n",
              "      <td>-629</td>\n",
              "      <td>-702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46840\\t46840\\tMW\\tFP1\\t7\\t889\\t-6</td>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>-17</td>\n",
              "      <td>-28</td>\n",
              "      <td>-46</td>\n",
              "      <td>-74</td>\n",
              "      <td>-98</td>\n",
              "      <td>-122</td>\n",
              "      <td>-139</td>\n",
              "      <td>-152</td>\n",
              "      <td>-165</td>\n",
              "      <td>-154</td>\n",
              "      <td>-131</td>\n",
              "      <td>-122</td>\n",
              "      <td>-131</td>\n",
              "      <td>-147</td>\n",
              "      <td>-141</td>\n",
              "      <td>-102</td>\n",
              "      <td>-71</td>\n",
              "      <td>-55</td>\n",
              "      <td>-39</td>\n",
              "      <td>-27</td>\n",
              "      <td>-12</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>43</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>73</td>\n",
              "      <td>...</td>\n",
              "      <td>419</td>\n",
              "      <td>408</td>\n",
              "      <td>391</td>\n",
              "      <td>372</td>\n",
              "      <td>353</td>\n",
              "      <td>340</td>\n",
              "      <td>325</td>\n",
              "      <td>313</td>\n",
              "      <td>306</td>\n",
              "      <td>294</td>\n",
              "      <td>282</td>\n",
              "      <td>269</td>\n",
              "      <td>256</td>\n",
              "      <td>243</td>\n",
              "      <td>240</td>\n",
              "      <td>234</td>\n",
              "      <td>217</td>\n",
              "      <td>203</td>\n",
              "      <td>200</td>\n",
              "      <td>197</td>\n",
              "      <td>182</td>\n",
              "      <td>160</td>\n",
              "      <td>141</td>\n",
              "      <td>137</td>\n",
              "      <td>133</td>\n",
              "      <td>128</td>\n",
              "      <td>122</td>\n",
              "      <td>112</td>\n",
              "      <td>98</td>\n",
              "      <td>90</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>-20</td>\n",
              "      <td>-70</td>\n",
              "      <td>-137</td>\n",
              "      <td>-220</td>\n",
              "      <td>-324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32187\\t32187\\tMW\\tFP1\\t4\\t952\\t113</td>\n",
              "      <td>116</td>\n",
              "      <td>113</td>\n",
              "      <td>108</td>\n",
              "      <td>107</td>\n",
              "      <td>96</td>\n",
              "      <td>80</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>83</td>\n",
              "      <td>103</td>\n",
              "      <td>101</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>64</td>\n",
              "      <td>73</td>\n",
              "      <td>68</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>67</td>\n",
              "      <td>71</td>\n",
              "      <td>56</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "      <td>45</td>\n",
              "      <td>53</td>\n",
              "      <td>58</td>\n",
              "      <td>60</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>55</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>51</td>\n",
              "      <td>39</td>\n",
              "      <td>41</td>\n",
              "      <td>...</td>\n",
              "      <td>1178</td>\n",
              "      <td>1205</td>\n",
              "      <td>1194</td>\n",
              "      <td>1157</td>\n",
              "      <td>1114</td>\n",
              "      <td>1099</td>\n",
              "      <td>1107</td>\n",
              "      <td>1116</td>\n",
              "      <td>1128</td>\n",
              "      <td>1140</td>\n",
              "      <td>1148</td>\n",
              "      <td>1149</td>\n",
              "      <td>1146</td>\n",
              "      <td>1142</td>\n",
              "      <td>1128</td>\n",
              "      <td>1107</td>\n",
              "      <td>1080</td>\n",
              "      <td>1053</td>\n",
              "      <td>1029</td>\n",
              "      <td>1003</td>\n",
              "      <td>977</td>\n",
              "      <td>947</td>\n",
              "      <td>918</td>\n",
              "      <td>890</td>\n",
              "      <td>864</td>\n",
              "      <td>835</td>\n",
              "      <td>806</td>\n",
              "      <td>777</td>\n",
              "      <td>752</td>\n",
              "      <td>724</td>\n",
              "      <td>697</td>\n",
              "      <td>673</td>\n",
              "      <td>645</td>\n",
              "      <td>615</td>\n",
              "      <td>577</td>\n",
              "      <td>515</td>\n",
              "      <td>418</td>\n",
              "      <td>296</td>\n",
              "      <td>167</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37787\\t37787\\tMW\\tFP1\\t9\\t1015\\t116</td>\n",
              "      <td>300</td>\n",
              "      <td>438</td>\n",
              "      <td>436</td>\n",
              "      <td>323</td>\n",
              "      <td>228</td>\n",
              "      <td>201</td>\n",
              "      <td>192</td>\n",
              "      <td>150</td>\n",
              "      <td>72</td>\n",
              "      <td>-13</td>\n",
              "      <td>-100</td>\n",
              "      <td>-156</td>\n",
              "      <td>-178</td>\n",
              "      <td>-173</td>\n",
              "      <td>-150</td>\n",
              "      <td>-107</td>\n",
              "      <td>-53</td>\n",
              "      <td>-12</td>\n",
              "      <td>-9</td>\n",
              "      <td>-41</td>\n",
              "      <td>-82</td>\n",
              "      <td>-101</td>\n",
              "      <td>-118</td>\n",
              "      <td>-117</td>\n",
              "      <td>-91</td>\n",
              "      <td>-60</td>\n",
              "      <td>-39</td>\n",
              "      <td>-22</td>\n",
              "      <td>-12</td>\n",
              "      <td>-22</td>\n",
              "      <td>-46</td>\n",
              "      <td>-70</td>\n",
              "      <td>-76</td>\n",
              "      <td>-73</td>\n",
              "      <td>-67</td>\n",
              "      <td>-66</td>\n",
              "      <td>-59</td>\n",
              "      <td>-45</td>\n",
              "      <td>-35</td>\n",
              "      <td>...</td>\n",
              "      <td>-9</td>\n",
              "      <td>85</td>\n",
              "      <td>243</td>\n",
              "      <td>317</td>\n",
              "      <td>300</td>\n",
              "      <td>230</td>\n",
              "      <td>135</td>\n",
              "      <td>76</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>-11</td>\n",
              "      <td>-113</td>\n",
              "      <td>-226</td>\n",
              "      <td>-322</td>\n",
              "      <td>-387</td>\n",
              "      <td>-421</td>\n",
              "      <td>-409</td>\n",
              "      <td>-349</td>\n",
              "      <td>-273</td>\n",
              "      <td>-222</td>\n",
              "      <td>-228</td>\n",
              "      <td>-227</td>\n",
              "      <td>-101</td>\n",
              "      <td>39</td>\n",
              "      <td>21</td>\n",
              "      <td>-135</td>\n",
              "      <td>-268</td>\n",
              "      <td>-306</td>\n",
              "      <td>-289</td>\n",
              "      <td>-281</td>\n",
              "      <td>-314</td>\n",
              "      <td>-404</td>\n",
              "      <td>-530</td>\n",
              "      <td>-658</td>\n",
              "      <td>-738</td>\n",
              "      <td>-774</td>\n",
              "      <td>-796</td>\n",
              "      <td>-805</td>\n",
              "      <td>-806</td>\n",
              "      <td>-825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 875 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   0     1     2     3    ...  871  872   873   874\n",
              "0   25253\\t25253\\tMW\\tFP1\\t1\\t952\\t152   154   155   148  ... -601 -901 -1157 -1364\n",
              "1    4279\\t4279\\tMW\\tFP1\\t0\\t952\\t1261  1209  1158  1116  ... -513 -556  -629  -702\n",
              "2    46840\\t46840\\tMW\\tFP1\\t7\\t889\\t-6    27    37    20  ...  -70 -137  -220  -324\n",
              "3   32187\\t32187\\tMW\\tFP1\\t4\\t952\\t113   116   113   108  ...  418  296   167    23\n",
              "4  37787\\t37787\\tMW\\tFP1\\t9\\t1015\\t116   300   438   436  ... -796 -805  -806  -825\n",
              "\n",
              "[5 rows x 875 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lfSm2bwzgwF",
        "colab_type": "code",
        "outputId": "6f186ebd-652f-4c63-fbc3-15d1bdbfc1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# https://stackoverflow.com/questions/14745022/how-to-split-a-column-into-two-columns\n",
        "tmp = raw[0].str.split('\\t').tolist()[:-1] # [:-1] means exclude last\n",
        "df = pd.DataFrame(tmp,columns = [\"id\", \"event\" , \"device\" , \"channel\" , \"code\" , \"size\" , \"0\"] )\n",
        "df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>event</th>\n",
              "      <th>device</th>\n",
              "      <th>channel</th>\n",
              "      <th>code</th>\n",
              "      <th>size</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25253</td>\n",
              "      <td>25253</td>\n",
              "      <td>MW</td>\n",
              "      <td>FP1</td>\n",
              "      <td>1</td>\n",
              "      <td>952</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4279</td>\n",
              "      <td>4279</td>\n",
              "      <td>MW</td>\n",
              "      <td>FP1</td>\n",
              "      <td>0</td>\n",
              "      <td>952</td>\n",
              "      <td>1261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46840</td>\n",
              "      <td>46840</td>\n",
              "      <td>MW</td>\n",
              "      <td>FP1</td>\n",
              "      <td>7</td>\n",
              "      <td>889</td>\n",
              "      <td>-6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  event device channel code size     0\n",
              "0  25253  25253     MW     FP1    1  952   152\n",
              "1   4279   4279     MW     FP1    0  952  1261\n",
              "2  46840  46840     MW     FP1    7  889    -6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z4vgtGhzgwH",
        "colab_type": "code",
        "outputId": "a757793b-f1f2-43a8-e70b-b698343afe75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "to_concat = raw[:-1].drop(0,axis=1)\n",
        "to_concat.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>835</th>\n",
              "      <th>836</th>\n",
              "      <th>837</th>\n",
              "      <th>838</th>\n",
              "      <th>839</th>\n",
              "      <th>840</th>\n",
              "      <th>841</th>\n",
              "      <th>842</th>\n",
              "      <th>843</th>\n",
              "      <th>844</th>\n",
              "      <th>845</th>\n",
              "      <th>846</th>\n",
              "      <th>847</th>\n",
              "      <th>848</th>\n",
              "      <th>849</th>\n",
              "      <th>850</th>\n",
              "      <th>851</th>\n",
              "      <th>852</th>\n",
              "      <th>853</th>\n",
              "      <th>854</th>\n",
              "      <th>855</th>\n",
              "      <th>856</th>\n",
              "      <th>857</th>\n",
              "      <th>858</th>\n",
              "      <th>859</th>\n",
              "      <th>860</th>\n",
              "      <th>861</th>\n",
              "      <th>862</th>\n",
              "      <th>863</th>\n",
              "      <th>864</th>\n",
              "      <th>865</th>\n",
              "      <th>866</th>\n",
              "      <th>867</th>\n",
              "      <th>868</th>\n",
              "      <th>869</th>\n",
              "      <th>870</th>\n",
              "      <th>871</th>\n",
              "      <th>872</th>\n",
              "      <th>873</th>\n",
              "      <th>874</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>154</td>\n",
              "      <td>155</td>\n",
              "      <td>148</td>\n",
              "      <td>136</td>\n",
              "      <td>137</td>\n",
              "      <td>129</td>\n",
              "      <td>104</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>101</td>\n",
              "      <td>88</td>\n",
              "      <td>82</td>\n",
              "      <td>92</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>104</td>\n",
              "      <td>117</td>\n",
              "      <td>118</td>\n",
              "      <td>117</td>\n",
              "      <td>114</td>\n",
              "      <td>113</td>\n",
              "      <td>112</td>\n",
              "      <td>106</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>85</td>\n",
              "      <td>69</td>\n",
              "      <td>74</td>\n",
              "      <td>86</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "      <td>77</td>\n",
              "      <td>...</td>\n",
              "      <td>1098</td>\n",
              "      <td>1064</td>\n",
              "      <td>1030</td>\n",
              "      <td>995</td>\n",
              "      <td>960</td>\n",
              "      <td>925</td>\n",
              "      <td>896</td>\n",
              "      <td>865</td>\n",
              "      <td>833</td>\n",
              "      <td>803</td>\n",
              "      <td>773</td>\n",
              "      <td>745</td>\n",
              "      <td>721</td>\n",
              "      <td>696</td>\n",
              "      <td>674</td>\n",
              "      <td>650</td>\n",
              "      <td>629</td>\n",
              "      <td>608</td>\n",
              "      <td>585</td>\n",
              "      <td>564</td>\n",
              "      <td>544</td>\n",
              "      <td>524</td>\n",
              "      <td>506</td>\n",
              "      <td>488</td>\n",
              "      <td>470</td>\n",
              "      <td>453</td>\n",
              "      <td>438</td>\n",
              "      <td>423</td>\n",
              "      <td>404</td>\n",
              "      <td>373</td>\n",
              "      <td>323</td>\n",
              "      <td>249</td>\n",
              "      <td>156</td>\n",
              "      <td>48</td>\n",
              "      <td>-92</td>\n",
              "      <td>-302</td>\n",
              "      <td>-601</td>\n",
              "      <td>-901</td>\n",
              "      <td>-1157</td>\n",
              "      <td>-1364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1209</td>\n",
              "      <td>1158</td>\n",
              "      <td>1116</td>\n",
              "      <td>1090</td>\n",
              "      <td>1073</td>\n",
              "      <td>1059</td>\n",
              "      <td>1033</td>\n",
              "      <td>1003</td>\n",
              "      <td>967</td>\n",
              "      <td>930</td>\n",
              "      <td>892</td>\n",
              "      <td>845</td>\n",
              "      <td>789</td>\n",
              "      <td>762</td>\n",
              "      <td>778</td>\n",
              "      <td>773</td>\n",
              "      <td>721</td>\n",
              "      <td>660</td>\n",
              "      <td>617</td>\n",
              "      <td>589</td>\n",
              "      <td>568</td>\n",
              "      <td>539</td>\n",
              "      <td>507</td>\n",
              "      <td>487</td>\n",
              "      <td>486</td>\n",
              "      <td>485</td>\n",
              "      <td>482</td>\n",
              "      <td>469</td>\n",
              "      <td>441</td>\n",
              "      <td>409</td>\n",
              "      <td>371</td>\n",
              "      <td>324</td>\n",
              "      <td>274</td>\n",
              "      <td>237</td>\n",
              "      <td>219</td>\n",
              "      <td>199</td>\n",
              "      <td>183</td>\n",
              "      <td>166</td>\n",
              "      <td>138</td>\n",
              "      <td>122</td>\n",
              "      <td>...</td>\n",
              "      <td>-49</td>\n",
              "      <td>-55</td>\n",
              "      <td>-62</td>\n",
              "      <td>-61</td>\n",
              "      <td>-59</td>\n",
              "      <td>-67</td>\n",
              "      <td>-81</td>\n",
              "      <td>-90</td>\n",
              "      <td>-93</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-107</td>\n",
              "      <td>-120</td>\n",
              "      <td>-134</td>\n",
              "      <td>-149</td>\n",
              "      <td>-165</td>\n",
              "      <td>-177</td>\n",
              "      <td>-179</td>\n",
              "      <td>-181</td>\n",
              "      <td>-181</td>\n",
              "      <td>-174</td>\n",
              "      <td>-179</td>\n",
              "      <td>-195</td>\n",
              "      <td>-212</td>\n",
              "      <td>-237</td>\n",
              "      <td>-266</td>\n",
              "      <td>-280</td>\n",
              "      <td>-301</td>\n",
              "      <td>-339</td>\n",
              "      <td>-359</td>\n",
              "      <td>-363</td>\n",
              "      <td>-380</td>\n",
              "      <td>-419</td>\n",
              "      <td>-459</td>\n",
              "      <td>-488</td>\n",
              "      <td>-494</td>\n",
              "      <td>-513</td>\n",
              "      <td>-556</td>\n",
              "      <td>-629</td>\n",
              "      <td>-702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>-17</td>\n",
              "      <td>-28</td>\n",
              "      <td>-46</td>\n",
              "      <td>-74</td>\n",
              "      <td>-98</td>\n",
              "      <td>-122</td>\n",
              "      <td>-139</td>\n",
              "      <td>-152</td>\n",
              "      <td>-165</td>\n",
              "      <td>-154</td>\n",
              "      <td>-131</td>\n",
              "      <td>-122</td>\n",
              "      <td>-131</td>\n",
              "      <td>-147</td>\n",
              "      <td>-141</td>\n",
              "      <td>-102</td>\n",
              "      <td>-71</td>\n",
              "      <td>-55</td>\n",
              "      <td>-39</td>\n",
              "      <td>-27</td>\n",
              "      <td>-12</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>43</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>73</td>\n",
              "      <td>128</td>\n",
              "      <td>...</td>\n",
              "      <td>419</td>\n",
              "      <td>408</td>\n",
              "      <td>391</td>\n",
              "      <td>372</td>\n",
              "      <td>353</td>\n",
              "      <td>340</td>\n",
              "      <td>325</td>\n",
              "      <td>313</td>\n",
              "      <td>306</td>\n",
              "      <td>294</td>\n",
              "      <td>282</td>\n",
              "      <td>269</td>\n",
              "      <td>256</td>\n",
              "      <td>243</td>\n",
              "      <td>240</td>\n",
              "      <td>234</td>\n",
              "      <td>217</td>\n",
              "      <td>203</td>\n",
              "      <td>200</td>\n",
              "      <td>197</td>\n",
              "      <td>182</td>\n",
              "      <td>160</td>\n",
              "      <td>141</td>\n",
              "      <td>137</td>\n",
              "      <td>133</td>\n",
              "      <td>128</td>\n",
              "      <td>122</td>\n",
              "      <td>112</td>\n",
              "      <td>98</td>\n",
              "      <td>90</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>-20</td>\n",
              "      <td>-70</td>\n",
              "      <td>-137</td>\n",
              "      <td>-220</td>\n",
              "      <td>-324</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 874 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    1     2     3     4     5     6    ...  869  870  871  872   873   874\n",
              "0   154   155   148   136   137   129  ...  -92 -302 -601 -901 -1157 -1364\n",
              "1  1209  1158  1116  1090  1073  1059  ... -488 -494 -513 -556  -629  -702\n",
              "2    27    37    20     8    10     3  ...    4  -20  -70 -137  -220  -324\n",
              "\n",
              "[3 rows x 874 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osx3O6tpzgwJ",
        "colab_type": "code",
        "outputId": "2786afef-0478-4208-85fd-843789e8a24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "data = pd.concat([df,to_concat], axis =1)\n",
        "data = data.drop(['device','channel'],axis =1)\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>event</th>\n",
              "      <th>code</th>\n",
              "      <th>size</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>...</th>\n",
              "      <th>835</th>\n",
              "      <th>836</th>\n",
              "      <th>837</th>\n",
              "      <th>838</th>\n",
              "      <th>839</th>\n",
              "      <th>840</th>\n",
              "      <th>841</th>\n",
              "      <th>842</th>\n",
              "      <th>843</th>\n",
              "      <th>844</th>\n",
              "      <th>845</th>\n",
              "      <th>846</th>\n",
              "      <th>847</th>\n",
              "      <th>848</th>\n",
              "      <th>849</th>\n",
              "      <th>850</th>\n",
              "      <th>851</th>\n",
              "      <th>852</th>\n",
              "      <th>853</th>\n",
              "      <th>854</th>\n",
              "      <th>855</th>\n",
              "      <th>856</th>\n",
              "      <th>857</th>\n",
              "      <th>858</th>\n",
              "      <th>859</th>\n",
              "      <th>860</th>\n",
              "      <th>861</th>\n",
              "      <th>862</th>\n",
              "      <th>863</th>\n",
              "      <th>864</th>\n",
              "      <th>865</th>\n",
              "      <th>866</th>\n",
              "      <th>867</th>\n",
              "      <th>868</th>\n",
              "      <th>869</th>\n",
              "      <th>870</th>\n",
              "      <th>871</th>\n",
              "      <th>872</th>\n",
              "      <th>873</th>\n",
              "      <th>874</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25253</td>\n",
              "      <td>25253</td>\n",
              "      <td>1</td>\n",
              "      <td>952</td>\n",
              "      <td>152</td>\n",
              "      <td>154</td>\n",
              "      <td>155</td>\n",
              "      <td>148</td>\n",
              "      <td>136</td>\n",
              "      <td>137</td>\n",
              "      <td>129</td>\n",
              "      <td>104</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>101</td>\n",
              "      <td>88</td>\n",
              "      <td>82</td>\n",
              "      <td>92</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>104</td>\n",
              "      <td>117</td>\n",
              "      <td>118</td>\n",
              "      <td>117</td>\n",
              "      <td>114</td>\n",
              "      <td>113</td>\n",
              "      <td>112</td>\n",
              "      <td>106</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>85</td>\n",
              "      <td>69</td>\n",
              "      <td>...</td>\n",
              "      <td>1098</td>\n",
              "      <td>1064</td>\n",
              "      <td>1030</td>\n",
              "      <td>995</td>\n",
              "      <td>960</td>\n",
              "      <td>925</td>\n",
              "      <td>896</td>\n",
              "      <td>865</td>\n",
              "      <td>833</td>\n",
              "      <td>803</td>\n",
              "      <td>773</td>\n",
              "      <td>745</td>\n",
              "      <td>721</td>\n",
              "      <td>696</td>\n",
              "      <td>674</td>\n",
              "      <td>650</td>\n",
              "      <td>629</td>\n",
              "      <td>608</td>\n",
              "      <td>585</td>\n",
              "      <td>564</td>\n",
              "      <td>544</td>\n",
              "      <td>524</td>\n",
              "      <td>506</td>\n",
              "      <td>488</td>\n",
              "      <td>470</td>\n",
              "      <td>453</td>\n",
              "      <td>438</td>\n",
              "      <td>423</td>\n",
              "      <td>404</td>\n",
              "      <td>373</td>\n",
              "      <td>323</td>\n",
              "      <td>249</td>\n",
              "      <td>156</td>\n",
              "      <td>48</td>\n",
              "      <td>-92</td>\n",
              "      <td>-302</td>\n",
              "      <td>-601</td>\n",
              "      <td>-901</td>\n",
              "      <td>-1157</td>\n",
              "      <td>-1364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4279</td>\n",
              "      <td>4279</td>\n",
              "      <td>0</td>\n",
              "      <td>952</td>\n",
              "      <td>1261</td>\n",
              "      <td>1209</td>\n",
              "      <td>1158</td>\n",
              "      <td>1116</td>\n",
              "      <td>1090</td>\n",
              "      <td>1073</td>\n",
              "      <td>1059</td>\n",
              "      <td>1033</td>\n",
              "      <td>1003</td>\n",
              "      <td>967</td>\n",
              "      <td>930</td>\n",
              "      <td>892</td>\n",
              "      <td>845</td>\n",
              "      <td>789</td>\n",
              "      <td>762</td>\n",
              "      <td>778</td>\n",
              "      <td>773</td>\n",
              "      <td>721</td>\n",
              "      <td>660</td>\n",
              "      <td>617</td>\n",
              "      <td>589</td>\n",
              "      <td>568</td>\n",
              "      <td>539</td>\n",
              "      <td>507</td>\n",
              "      <td>487</td>\n",
              "      <td>486</td>\n",
              "      <td>485</td>\n",
              "      <td>482</td>\n",
              "      <td>469</td>\n",
              "      <td>441</td>\n",
              "      <td>409</td>\n",
              "      <td>371</td>\n",
              "      <td>324</td>\n",
              "      <td>274</td>\n",
              "      <td>237</td>\n",
              "      <td>219</td>\n",
              "      <td>...</td>\n",
              "      <td>-49</td>\n",
              "      <td>-55</td>\n",
              "      <td>-62</td>\n",
              "      <td>-61</td>\n",
              "      <td>-59</td>\n",
              "      <td>-67</td>\n",
              "      <td>-81</td>\n",
              "      <td>-90</td>\n",
              "      <td>-93</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-107</td>\n",
              "      <td>-120</td>\n",
              "      <td>-134</td>\n",
              "      <td>-149</td>\n",
              "      <td>-165</td>\n",
              "      <td>-177</td>\n",
              "      <td>-179</td>\n",
              "      <td>-181</td>\n",
              "      <td>-181</td>\n",
              "      <td>-174</td>\n",
              "      <td>-179</td>\n",
              "      <td>-195</td>\n",
              "      <td>-212</td>\n",
              "      <td>-237</td>\n",
              "      <td>-266</td>\n",
              "      <td>-280</td>\n",
              "      <td>-301</td>\n",
              "      <td>-339</td>\n",
              "      <td>-359</td>\n",
              "      <td>-363</td>\n",
              "      <td>-380</td>\n",
              "      <td>-419</td>\n",
              "      <td>-459</td>\n",
              "      <td>-488</td>\n",
              "      <td>-494</td>\n",
              "      <td>-513</td>\n",
              "      <td>-556</td>\n",
              "      <td>-629</td>\n",
              "      <td>-702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46840</td>\n",
              "      <td>46840</td>\n",
              "      <td>7</td>\n",
              "      <td>889</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>-17</td>\n",
              "      <td>-28</td>\n",
              "      <td>-46</td>\n",
              "      <td>-74</td>\n",
              "      <td>-98</td>\n",
              "      <td>-122</td>\n",
              "      <td>-139</td>\n",
              "      <td>-152</td>\n",
              "      <td>-165</td>\n",
              "      <td>-154</td>\n",
              "      <td>-131</td>\n",
              "      <td>-122</td>\n",
              "      <td>-131</td>\n",
              "      <td>-147</td>\n",
              "      <td>-141</td>\n",
              "      <td>-102</td>\n",
              "      <td>-71</td>\n",
              "      <td>-55</td>\n",
              "      <td>-39</td>\n",
              "      <td>-27</td>\n",
              "      <td>-12</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>419</td>\n",
              "      <td>408</td>\n",
              "      <td>391</td>\n",
              "      <td>372</td>\n",
              "      <td>353</td>\n",
              "      <td>340</td>\n",
              "      <td>325</td>\n",
              "      <td>313</td>\n",
              "      <td>306</td>\n",
              "      <td>294</td>\n",
              "      <td>282</td>\n",
              "      <td>269</td>\n",
              "      <td>256</td>\n",
              "      <td>243</td>\n",
              "      <td>240</td>\n",
              "      <td>234</td>\n",
              "      <td>217</td>\n",
              "      <td>203</td>\n",
              "      <td>200</td>\n",
              "      <td>197</td>\n",
              "      <td>182</td>\n",
              "      <td>160</td>\n",
              "      <td>141</td>\n",
              "      <td>137</td>\n",
              "      <td>133</td>\n",
              "      <td>128</td>\n",
              "      <td>122</td>\n",
              "      <td>112</td>\n",
              "      <td>98</td>\n",
              "      <td>90</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>-20</td>\n",
              "      <td>-70</td>\n",
              "      <td>-137</td>\n",
              "      <td>-220</td>\n",
              "      <td>-324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32187</td>\n",
              "      <td>32187</td>\n",
              "      <td>4</td>\n",
              "      <td>952</td>\n",
              "      <td>113</td>\n",
              "      <td>116</td>\n",
              "      <td>113</td>\n",
              "      <td>108</td>\n",
              "      <td>107</td>\n",
              "      <td>96</td>\n",
              "      <td>80</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>83</td>\n",
              "      <td>103</td>\n",
              "      <td>101</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>64</td>\n",
              "      <td>73</td>\n",
              "      <td>68</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>67</td>\n",
              "      <td>71</td>\n",
              "      <td>56</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "      <td>45</td>\n",
              "      <td>53</td>\n",
              "      <td>58</td>\n",
              "      <td>60</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>55</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>42</td>\n",
              "      <td>...</td>\n",
              "      <td>1178</td>\n",
              "      <td>1205</td>\n",
              "      <td>1194</td>\n",
              "      <td>1157</td>\n",
              "      <td>1114</td>\n",
              "      <td>1099</td>\n",
              "      <td>1107</td>\n",
              "      <td>1116</td>\n",
              "      <td>1128</td>\n",
              "      <td>1140</td>\n",
              "      <td>1148</td>\n",
              "      <td>1149</td>\n",
              "      <td>1146</td>\n",
              "      <td>1142</td>\n",
              "      <td>1128</td>\n",
              "      <td>1107</td>\n",
              "      <td>1080</td>\n",
              "      <td>1053</td>\n",
              "      <td>1029</td>\n",
              "      <td>1003</td>\n",
              "      <td>977</td>\n",
              "      <td>947</td>\n",
              "      <td>918</td>\n",
              "      <td>890</td>\n",
              "      <td>864</td>\n",
              "      <td>835</td>\n",
              "      <td>806</td>\n",
              "      <td>777</td>\n",
              "      <td>752</td>\n",
              "      <td>724</td>\n",
              "      <td>697</td>\n",
              "      <td>673</td>\n",
              "      <td>645</td>\n",
              "      <td>615</td>\n",
              "      <td>577</td>\n",
              "      <td>515</td>\n",
              "      <td>418</td>\n",
              "      <td>296</td>\n",
              "      <td>167</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37787</td>\n",
              "      <td>37787</td>\n",
              "      <td>9</td>\n",
              "      <td>1015</td>\n",
              "      <td>116</td>\n",
              "      <td>300</td>\n",
              "      <td>438</td>\n",
              "      <td>436</td>\n",
              "      <td>323</td>\n",
              "      <td>228</td>\n",
              "      <td>201</td>\n",
              "      <td>192</td>\n",
              "      <td>150</td>\n",
              "      <td>72</td>\n",
              "      <td>-13</td>\n",
              "      <td>-100</td>\n",
              "      <td>-156</td>\n",
              "      <td>-178</td>\n",
              "      <td>-173</td>\n",
              "      <td>-150</td>\n",
              "      <td>-107</td>\n",
              "      <td>-53</td>\n",
              "      <td>-12</td>\n",
              "      <td>-9</td>\n",
              "      <td>-41</td>\n",
              "      <td>-82</td>\n",
              "      <td>-101</td>\n",
              "      <td>-118</td>\n",
              "      <td>-117</td>\n",
              "      <td>-91</td>\n",
              "      <td>-60</td>\n",
              "      <td>-39</td>\n",
              "      <td>-22</td>\n",
              "      <td>-12</td>\n",
              "      <td>-22</td>\n",
              "      <td>-46</td>\n",
              "      <td>-70</td>\n",
              "      <td>-76</td>\n",
              "      <td>-73</td>\n",
              "      <td>-67</td>\n",
              "      <td>...</td>\n",
              "      <td>-9</td>\n",
              "      <td>85</td>\n",
              "      <td>243</td>\n",
              "      <td>317</td>\n",
              "      <td>300</td>\n",
              "      <td>230</td>\n",
              "      <td>135</td>\n",
              "      <td>76</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>-11</td>\n",
              "      <td>-113</td>\n",
              "      <td>-226</td>\n",
              "      <td>-322</td>\n",
              "      <td>-387</td>\n",
              "      <td>-421</td>\n",
              "      <td>-409</td>\n",
              "      <td>-349</td>\n",
              "      <td>-273</td>\n",
              "      <td>-222</td>\n",
              "      <td>-228</td>\n",
              "      <td>-227</td>\n",
              "      <td>-101</td>\n",
              "      <td>39</td>\n",
              "      <td>21</td>\n",
              "      <td>-135</td>\n",
              "      <td>-268</td>\n",
              "      <td>-306</td>\n",
              "      <td>-289</td>\n",
              "      <td>-281</td>\n",
              "      <td>-314</td>\n",
              "      <td>-404</td>\n",
              "      <td>-530</td>\n",
              "      <td>-658</td>\n",
              "      <td>-738</td>\n",
              "      <td>-774</td>\n",
              "      <td>-796</td>\n",
              "      <td>-805</td>\n",
              "      <td>-806</td>\n",
              "      <td>-825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 879 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  event code  size     0     1  ...  869  870  871  872   873   874\n",
              "0  25253  25253    1   952   152   154  ...  -92 -302 -601 -901 -1157 -1364\n",
              "1   4279   4279    0   952  1261  1209  ... -488 -494 -513 -556  -629  -702\n",
              "2  46840  46840    7   889    -6    27  ...    4  -20  -70 -137  -220  -324\n",
              "3  32187  32187    4   952   113   116  ...  577  515  418  296   167    23\n",
              "4  37787  37787    9  1015   116   300  ... -738 -774 -796 -805  -806  -825\n",
              "\n",
              "[5 rows x 879 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnMrVpiczgwK",
        "colab_type": "text"
      },
      "source": [
        "### Droped 'device' and 'channel', since they are of not in use. this dataset is single channel\n",
        "... I am using *MindWave*\n",
        "\n",
        "#### Now its time to give a shit about the data we are working with... rather than treating it as 'just data'\n",
        "\n",
        "[event]: id, a integer, used to distinguish the same event captured at different brain locations, used only by multichannel devices (all except MW).\n",
        "\n",
        "[size]: a integer, to identify the size in number of values captured in the 2 seconds of this signal, since the Hz of each device varies, in \"theory\" the value is close to 512Hz for MW, 128Hz for EP, 220Hz for MU & 128Hz for IN, for each of the 2 seconds.\n",
        "\n",
        "[data]: a coma separated set of numbers, with the time-series amplitude of the signal, each device uses a different precision to identify the electrical potential captured from the brain: integers in the case of MW & MU or real numbers in the case of EP & IN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGeryz0lzgwL",
        "colab_type": "text"
      },
      "source": [
        "### I have truncated the data in excel to make it square (not a *jagged* array) \n",
        "* event is of no use\n",
        "* size appears to be of non use \n",
        "* I see no point in keeping ID \n",
        "\n",
        "**I have no clue what to do with [data]...**\n",
        "\n",
        "\n",
        "[data - proper definition]: a time-series signal, where the y-axis is the voltage.... its that fucking simple, no need for big words \n",
        "\n",
        "**I'm going back and labeling *data* as 0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-zp0sSczgwM",
        "colab_type": "code",
        "outputId": "2d6d887b-b80e-4305-ace6-50a292218a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "df = data.drop(['id','event','size'],axis =1)\n",
        "df.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>835</th>\n",
              "      <th>836</th>\n",
              "      <th>837</th>\n",
              "      <th>838</th>\n",
              "      <th>839</th>\n",
              "      <th>840</th>\n",
              "      <th>841</th>\n",
              "      <th>842</th>\n",
              "      <th>843</th>\n",
              "      <th>844</th>\n",
              "      <th>845</th>\n",
              "      <th>846</th>\n",
              "      <th>847</th>\n",
              "      <th>848</th>\n",
              "      <th>849</th>\n",
              "      <th>850</th>\n",
              "      <th>851</th>\n",
              "      <th>852</th>\n",
              "      <th>853</th>\n",
              "      <th>854</th>\n",
              "      <th>855</th>\n",
              "      <th>856</th>\n",
              "      <th>857</th>\n",
              "      <th>858</th>\n",
              "      <th>859</th>\n",
              "      <th>860</th>\n",
              "      <th>861</th>\n",
              "      <th>862</th>\n",
              "      <th>863</th>\n",
              "      <th>864</th>\n",
              "      <th>865</th>\n",
              "      <th>866</th>\n",
              "      <th>867</th>\n",
              "      <th>868</th>\n",
              "      <th>869</th>\n",
              "      <th>870</th>\n",
              "      <th>871</th>\n",
              "      <th>872</th>\n",
              "      <th>873</th>\n",
              "      <th>874</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>152</td>\n",
              "      <td>154</td>\n",
              "      <td>155</td>\n",
              "      <td>148</td>\n",
              "      <td>136</td>\n",
              "      <td>137</td>\n",
              "      <td>129</td>\n",
              "      <td>104</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>101</td>\n",
              "      <td>88</td>\n",
              "      <td>82</td>\n",
              "      <td>92</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>104</td>\n",
              "      <td>117</td>\n",
              "      <td>118</td>\n",
              "      <td>117</td>\n",
              "      <td>114</td>\n",
              "      <td>113</td>\n",
              "      <td>112</td>\n",
              "      <td>106</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>99</td>\n",
              "      <td>88</td>\n",
              "      <td>91</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>85</td>\n",
              "      <td>69</td>\n",
              "      <td>74</td>\n",
              "      <td>86</td>\n",
              "      <td>90</td>\n",
              "      <td>...</td>\n",
              "      <td>1098</td>\n",
              "      <td>1064</td>\n",
              "      <td>1030</td>\n",
              "      <td>995</td>\n",
              "      <td>960</td>\n",
              "      <td>925</td>\n",
              "      <td>896</td>\n",
              "      <td>865</td>\n",
              "      <td>833</td>\n",
              "      <td>803</td>\n",
              "      <td>773</td>\n",
              "      <td>745</td>\n",
              "      <td>721</td>\n",
              "      <td>696</td>\n",
              "      <td>674</td>\n",
              "      <td>650</td>\n",
              "      <td>629</td>\n",
              "      <td>608</td>\n",
              "      <td>585</td>\n",
              "      <td>564</td>\n",
              "      <td>544</td>\n",
              "      <td>524</td>\n",
              "      <td>506</td>\n",
              "      <td>488</td>\n",
              "      <td>470</td>\n",
              "      <td>453</td>\n",
              "      <td>438</td>\n",
              "      <td>423</td>\n",
              "      <td>404</td>\n",
              "      <td>373</td>\n",
              "      <td>323</td>\n",
              "      <td>249</td>\n",
              "      <td>156</td>\n",
              "      <td>48</td>\n",
              "      <td>-92</td>\n",
              "      <td>-302</td>\n",
              "      <td>-601</td>\n",
              "      <td>-901</td>\n",
              "      <td>-1157</td>\n",
              "      <td>-1364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1261</td>\n",
              "      <td>1209</td>\n",
              "      <td>1158</td>\n",
              "      <td>1116</td>\n",
              "      <td>1090</td>\n",
              "      <td>1073</td>\n",
              "      <td>1059</td>\n",
              "      <td>1033</td>\n",
              "      <td>1003</td>\n",
              "      <td>967</td>\n",
              "      <td>930</td>\n",
              "      <td>892</td>\n",
              "      <td>845</td>\n",
              "      <td>789</td>\n",
              "      <td>762</td>\n",
              "      <td>778</td>\n",
              "      <td>773</td>\n",
              "      <td>721</td>\n",
              "      <td>660</td>\n",
              "      <td>617</td>\n",
              "      <td>589</td>\n",
              "      <td>568</td>\n",
              "      <td>539</td>\n",
              "      <td>507</td>\n",
              "      <td>487</td>\n",
              "      <td>486</td>\n",
              "      <td>485</td>\n",
              "      <td>482</td>\n",
              "      <td>469</td>\n",
              "      <td>441</td>\n",
              "      <td>409</td>\n",
              "      <td>371</td>\n",
              "      <td>324</td>\n",
              "      <td>274</td>\n",
              "      <td>237</td>\n",
              "      <td>219</td>\n",
              "      <td>199</td>\n",
              "      <td>183</td>\n",
              "      <td>166</td>\n",
              "      <td>...</td>\n",
              "      <td>-49</td>\n",
              "      <td>-55</td>\n",
              "      <td>-62</td>\n",
              "      <td>-61</td>\n",
              "      <td>-59</td>\n",
              "      <td>-67</td>\n",
              "      <td>-81</td>\n",
              "      <td>-90</td>\n",
              "      <td>-93</td>\n",
              "      <td>-93</td>\n",
              "      <td>-98</td>\n",
              "      <td>-107</td>\n",
              "      <td>-120</td>\n",
              "      <td>-134</td>\n",
              "      <td>-149</td>\n",
              "      <td>-165</td>\n",
              "      <td>-177</td>\n",
              "      <td>-179</td>\n",
              "      <td>-181</td>\n",
              "      <td>-181</td>\n",
              "      <td>-174</td>\n",
              "      <td>-179</td>\n",
              "      <td>-195</td>\n",
              "      <td>-212</td>\n",
              "      <td>-237</td>\n",
              "      <td>-266</td>\n",
              "      <td>-280</td>\n",
              "      <td>-301</td>\n",
              "      <td>-339</td>\n",
              "      <td>-359</td>\n",
              "      <td>-363</td>\n",
              "      <td>-380</td>\n",
              "      <td>-419</td>\n",
              "      <td>-459</td>\n",
              "      <td>-488</td>\n",
              "      <td>-494</td>\n",
              "      <td>-513</td>\n",
              "      <td>-556</td>\n",
              "      <td>-629</td>\n",
              "      <td>-702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>-17</td>\n",
              "      <td>-28</td>\n",
              "      <td>-46</td>\n",
              "      <td>-74</td>\n",
              "      <td>-98</td>\n",
              "      <td>-122</td>\n",
              "      <td>-139</td>\n",
              "      <td>-152</td>\n",
              "      <td>-165</td>\n",
              "      <td>-154</td>\n",
              "      <td>-131</td>\n",
              "      <td>-122</td>\n",
              "      <td>-131</td>\n",
              "      <td>-147</td>\n",
              "      <td>-141</td>\n",
              "      <td>-102</td>\n",
              "      <td>-71</td>\n",
              "      <td>-55</td>\n",
              "      <td>-39</td>\n",
              "      <td>-27</td>\n",
              "      <td>-12</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>43</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>...</td>\n",
              "      <td>419</td>\n",
              "      <td>408</td>\n",
              "      <td>391</td>\n",
              "      <td>372</td>\n",
              "      <td>353</td>\n",
              "      <td>340</td>\n",
              "      <td>325</td>\n",
              "      <td>313</td>\n",
              "      <td>306</td>\n",
              "      <td>294</td>\n",
              "      <td>282</td>\n",
              "      <td>269</td>\n",
              "      <td>256</td>\n",
              "      <td>243</td>\n",
              "      <td>240</td>\n",
              "      <td>234</td>\n",
              "      <td>217</td>\n",
              "      <td>203</td>\n",
              "      <td>200</td>\n",
              "      <td>197</td>\n",
              "      <td>182</td>\n",
              "      <td>160</td>\n",
              "      <td>141</td>\n",
              "      <td>137</td>\n",
              "      <td>133</td>\n",
              "      <td>128</td>\n",
              "      <td>122</td>\n",
              "      <td>112</td>\n",
              "      <td>98</td>\n",
              "      <td>90</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>-20</td>\n",
              "      <td>-70</td>\n",
              "      <td>-137</td>\n",
              "      <td>-220</td>\n",
              "      <td>-324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>113</td>\n",
              "      <td>116</td>\n",
              "      <td>113</td>\n",
              "      <td>108</td>\n",
              "      <td>107</td>\n",
              "      <td>96</td>\n",
              "      <td>80</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>83</td>\n",
              "      <td>103</td>\n",
              "      <td>101</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>54</td>\n",
              "      <td>64</td>\n",
              "      <td>73</td>\n",
              "      <td>68</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>67</td>\n",
              "      <td>71</td>\n",
              "      <td>56</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "      <td>45</td>\n",
              "      <td>53</td>\n",
              "      <td>58</td>\n",
              "      <td>60</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>55</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>51</td>\n",
              "      <td>39</td>\n",
              "      <td>...</td>\n",
              "      <td>1178</td>\n",
              "      <td>1205</td>\n",
              "      <td>1194</td>\n",
              "      <td>1157</td>\n",
              "      <td>1114</td>\n",
              "      <td>1099</td>\n",
              "      <td>1107</td>\n",
              "      <td>1116</td>\n",
              "      <td>1128</td>\n",
              "      <td>1140</td>\n",
              "      <td>1148</td>\n",
              "      <td>1149</td>\n",
              "      <td>1146</td>\n",
              "      <td>1142</td>\n",
              "      <td>1128</td>\n",
              "      <td>1107</td>\n",
              "      <td>1080</td>\n",
              "      <td>1053</td>\n",
              "      <td>1029</td>\n",
              "      <td>1003</td>\n",
              "      <td>977</td>\n",
              "      <td>947</td>\n",
              "      <td>918</td>\n",
              "      <td>890</td>\n",
              "      <td>864</td>\n",
              "      <td>835</td>\n",
              "      <td>806</td>\n",
              "      <td>777</td>\n",
              "      <td>752</td>\n",
              "      <td>724</td>\n",
              "      <td>697</td>\n",
              "      <td>673</td>\n",
              "      <td>645</td>\n",
              "      <td>615</td>\n",
              "      <td>577</td>\n",
              "      <td>515</td>\n",
              "      <td>418</td>\n",
              "      <td>296</td>\n",
              "      <td>167</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>116</td>\n",
              "      <td>300</td>\n",
              "      <td>438</td>\n",
              "      <td>436</td>\n",
              "      <td>323</td>\n",
              "      <td>228</td>\n",
              "      <td>201</td>\n",
              "      <td>192</td>\n",
              "      <td>150</td>\n",
              "      <td>72</td>\n",
              "      <td>-13</td>\n",
              "      <td>-100</td>\n",
              "      <td>-156</td>\n",
              "      <td>-178</td>\n",
              "      <td>-173</td>\n",
              "      <td>-150</td>\n",
              "      <td>-107</td>\n",
              "      <td>-53</td>\n",
              "      <td>-12</td>\n",
              "      <td>-9</td>\n",
              "      <td>-41</td>\n",
              "      <td>-82</td>\n",
              "      <td>-101</td>\n",
              "      <td>-118</td>\n",
              "      <td>-117</td>\n",
              "      <td>-91</td>\n",
              "      <td>-60</td>\n",
              "      <td>-39</td>\n",
              "      <td>-22</td>\n",
              "      <td>-12</td>\n",
              "      <td>-22</td>\n",
              "      <td>-46</td>\n",
              "      <td>-70</td>\n",
              "      <td>-76</td>\n",
              "      <td>-73</td>\n",
              "      <td>-67</td>\n",
              "      <td>-66</td>\n",
              "      <td>-59</td>\n",
              "      <td>-45</td>\n",
              "      <td>...</td>\n",
              "      <td>-9</td>\n",
              "      <td>85</td>\n",
              "      <td>243</td>\n",
              "      <td>317</td>\n",
              "      <td>300</td>\n",
              "      <td>230</td>\n",
              "      <td>135</td>\n",
              "      <td>76</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>-11</td>\n",
              "      <td>-113</td>\n",
              "      <td>-226</td>\n",
              "      <td>-322</td>\n",
              "      <td>-387</td>\n",
              "      <td>-421</td>\n",
              "      <td>-409</td>\n",
              "      <td>-349</td>\n",
              "      <td>-273</td>\n",
              "      <td>-222</td>\n",
              "      <td>-228</td>\n",
              "      <td>-227</td>\n",
              "      <td>-101</td>\n",
              "      <td>39</td>\n",
              "      <td>21</td>\n",
              "      <td>-135</td>\n",
              "      <td>-268</td>\n",
              "      <td>-306</td>\n",
              "      <td>-289</td>\n",
              "      <td>-281</td>\n",
              "      <td>-314</td>\n",
              "      <td>-404</td>\n",
              "      <td>-530</td>\n",
              "      <td>-658</td>\n",
              "      <td>-738</td>\n",
              "      <td>-774</td>\n",
              "      <td>-796</td>\n",
              "      <td>-805</td>\n",
              "      <td>-806</td>\n",
              "      <td>-825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 876 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  code     0     1     2     3     4     5  ...  868  869  870  871  872   873   874\n",
              "0    1   152   154   155   148   136   137  ...   48  -92 -302 -601 -901 -1157 -1364\n",
              "1    0  1261  1209  1158  1116  1090  1073  ... -459 -488 -494 -513 -556  -629  -702\n",
              "2    7    -6    27    37    20     8    10  ...   16    4  -20  -70 -137  -220  -324\n",
              "3    4   113   116   113   108   107    96  ...  615  577  515  418  296   167    23\n",
              "4    9   116   300   438   436   323   228  ... -658 -738 -774 -796 -805  -806  -825\n",
              "\n",
              "[5 rows x 876 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5LvBEUvzgwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(['code'],axis =1)\n",
        "y = df.code\n",
        "\n",
        "X.astype = int\n",
        "y.astype = int\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZibvd-5Rueq",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UWJGE8MRuqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "y_train , y_test = y_train[1:].to_numpy(), y_test[1:].to_numpy()\n",
        "X_train, X_test = X_train[1:], X_test[1:]\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "X_train_trans = mms.fit_transform(X_train)\n",
        "X_test_trans = mms.transform(X_test)\n",
        "\n",
        "maxlen = 50#240\n",
        "# X_train_trans_padded = sequence.pad_sequences(pd.DataFrame(X_train_trans).to_numpy(), maxlen=maxlen)\n",
        "# X_test_trans_padded  = sequence.pad_sequences(pd.DataFrame(X_test_trans).to_numpy(), maxlen=maxlen)\n",
        "seqTrain=sequence.pad_sequences(sequences= X_train_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post')\n",
        "seqTest=sequence.pad_sequences(sequences= X_test_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post')\n",
        "\n",
        "seqTrain = seqTrain.reshape((-1, maxlen, 1))\n",
        "seqTest = seqTest.reshape((-1, maxlen, 1))\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train_oneHot, y_test_oneHot = enc.fit_transform(y_train.reshape(-1, 1)), enc.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "y_train_c, y_test_c= to_categorical(y_train), to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BU15cOadMu",
        "colab_type": "code",
        "outputId": "c52e5d44-f62e-4fe2-ef05-08081f13ed97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(y_train_oneHot[:5])\n",
        "# print(y_train_c[:5]) # matrix \n",
        "\n",
        "X_train_trans.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 3)\t1.0\n",
            "  (1, 7)\t1.0\n",
            "  (2, 6)\t1.0\n",
            "  (3, 3)\t1.0\n",
            "  (4, 4)\t1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28651, 875)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUzVQsUv9wjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "71b36cf9-99a7-4b79-d709-c01e91f55eb8"
      },
      "source": [
        "v = X_train_trans[0]\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "# plt.plot(list(range(len(v)-1)),v[1:])\n",
        "plt.plot(v)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 864x216 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f13b103a080>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAADCCAYAAABDjaTwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydeXxcV332n3Nn36XRvtmWbcl77DhO\ncEKczQlJoCUFQpuUpeFtWN6y0wIBShug0JcXGqC8aSkJBFogiUlICEkge2Jn8SLvuyTL2nfNvm/n\n/ePOuZqR7szcGY00I+l8Px9/PvZopLnWzL33d57z/J4foZSCw+FwOBwOh8NZbgilPgAOh8PhcDgc\nDqcU8EKYw+FwOBwOh7Ms4YUwh8PhcDgcDmdZwgthDofD4XA4HM6yhBfCHA6Hw+FwOJxlCS+EORwO\nh8PhcDjLEnWpXri6upquWrWqVC/P4XA4HA6Hw1kmHD58eJJSWjPz8ZIVwqtWrUJHR0epXp7D4XA4\nHA6Hs0wghPTJPc6tERwOh8PhcDicZQkvhDkcDofD4XA4yxJeCHM4HA6Hw+FwliW8EOZwOBwOh8Ph\nLEt4IczhLGG6x714cF9PqQ+Dw+FwOJyypGSpERwOZ/75wIMHMOYJY/eGOrRWm0p9OBwOh8PhlBVc\nEeZwliihaBxjnjAA4NXz4yU+Gg6Hw+Fwyg9eCHM4S5Q/nhqR/v5612QJj4TD4XA4nPKEWyM4nCXK\nL97oxdpaMy5ptmFv5yQopSCElPqwOBwOh8MpG7gizOEsQRz+CI4PuvGeS5uwraUCk74wRj2hUh8W\nh8PhcDhlBVeEOZwlyKFeBwDgba12qARRBT4+4EaDzVDKw+JwOBwOp6zgijCHswQ53OeEVi1gS7MN\nGxqsUAsEJ4dcpT4sDofD4XDKCq4IczhLkBF3CI02PXRqFQCgvc6CE4PuEh8Vh8PhcDjlBVeEOZwl\niMMfht2klf59SbMNJ4fcoJSW8Kg4HA6HwykvFBXChJBbCCHnCSHdhJB7ZL7+A0LIseSfTkII34Pl\ncEqIwx+F3aST/r25yQZXIIohV7CER8XhcDgcTnmRsxAmhKgA3A/gVgAbAdxJCNmY+hxK6ecppdso\npdsA/BjA7+bjYDkcjjJERVgj/but1gwA6B73leqQOBwOh8MpO5QowlcA6KaU9lBKIwAeAXBbluff\nCeDhYhwch8PJH0opHP5ImiK8lhfCHA6Hw+HMQkkh3ARgIOXfg8nHZkEIWQmgFcDLcz80DodTCL5w\nDNE4TVOEq8w62E1aXJjghTCHw+FwOIxiN8vdAeAxSmlc7ouEkI8RQjoIIR0TExNFfmkOhwOIwzQA\npCnCALC2xowL4/5SHBKHw+FwOGWJkkJ4CEBLyr+bk4/JcQey2CIopT+llO6glO6oqalRfpQcDkcx\nU8lCuColNQIAbEYNvOFYKQ6Jw+FwOJyyREkhfAhAGyGklRCihVjsPjXzSYSQ9QAqAbxV3EPkcDj5\n4A5GAYiFbyo6tYBwTHazhsPhcDicZUnOQphSGgPwKQDPATgLYA+l9DQh5JuEkHenPPUOAI9QHlTK\n4ZSUUEQsdg0aVdrjWrWASCxRikPicDgcDqcsUTRZjlL6LIBnZzz2TzP+fW/xDovD4RRKMCpfCIuK\nMC+EORwOh8Nh8MlyHM4SIxQVi139rEJYxRVhDofD4XBS4IUwh7PEYIqwXpN+emu5R5jD4XA4nDR4\nIczhLDFCUiE8wyOs4h7hxYrTH0Eszt87DofDKTa8EOZwlhihaByEiJ7gVHRqAQkKXlAtMtyBKHZ8\n+0X8w2+Pl/pQOBwOZ8nBC2EOZ4kRisahV6tACEl7XJssjHnD3OLiv9/qRTxB8eSxYVyc5ANROBwO\np5jwQpjDWWKEoolZ/mBgWiHm9ojFA6UUjx8ZhEUvBvx0j/MR2RwOh1NMeCHM4SwxgtH4rOg0ANCq\nxce4Irx4OD/mRe9UAHddtQoAMO4NlfaAOBwOZ4nBC2EOZ4kRisZnNcoB09YIrggvHv7fy93QqQV8\n4G0rQQgw7gmX+pA4HA5nScELYQ5niZGpEJasEXEeobYY6Bzz4ukTI/j4NatRb9PDbtRi3MsLYQ6H\nwykmvBDmcJYYmTzCTBFmAzc45YsnFMXXnjgJrVrAXW9vBQDUWHSY4NYIDoezSPGGonD4I6CUlvpQ\n0uCFMIezxAhF4zBosynCvBAud+5/uRuHep347O422E1aAECtVc8VYQ6Hs2h5YG8PLvuXF1BmdTAv\nhDmcpUYwGZ82Eyk+jSvCZc+LZ8dw9dpqfPL6tdJjtRYd9whzOJxFiz8Sh1GjgiCQ3E9eQHghzCkL\nXIEIdn7nJRzuc5T6UBY9uT3CvBAuZwadAVyY8OOG9bVpjzfa9Bj3hhDl7x+Hw1mEBCIxGHXqUh/G\nLHghzCkLjg+6MeoJ4dvPnC31oSx6RI+wXCEsPsZTI8qb86NeAMDWloq0x5srjUhQYNTNfcIcDmfx\n4Q/HYZKx7ZUaXghzyoJgJAYAGONbv3NGVIQzN8uFYzw1opzpHBOHZqytNac93lRpAAAMOAMLfkwc\nDoczVwKRGIxarghzOLJM+CIAgBF3sMRHsvjJOFBDxXOEFwNd417UW/WwGTRpjzcnC+EhJz9HOBzO\n4sMfjsOk44owhyPLZLIbPkGBAQdXvAqFUprZI6xhijAvhPPlaL8TnlB0QV6re9w3Sw0GgAabAYQA\ng7wQ5nA4i5BAJAYDV4Q5HHkmfNOWiFc7J0p4JIubaJwiQSEbn8YV4cIIReN4z3+8ibt/0bEgrzfo\nDGJllXHW41q1gDqLHsMuXghzOJzFRyDCPcJlw/lRL7+ZlBmT3jDW1VnQYjdgLy+ECyYYFf2/LCEi\nFZ2GN8sVwmDSk3uwd/4TTULROBz+CBpsetmvVxg1cAUXRpnmcDicYhKIxLlHuByglOLmH+7FrT/a\nV+pD4aQw6QujxqLDpS2VODPsKfXhLFrCyUI4myLMm+Xyo38BrTpjHjERot5mkP261aCBhxfCHA6n\nTPDmYRnzR2LcI1wOdI2LHdlufjMpKyZ9EVSZtWivM2PIFYQvHCv1IS1KmCIsN1BDoxJDzKPxMhvr\nU+b0T00Xwu7A/F43RpLRaJkUYZtBA0+InxscDqf0PHF0EFvufR7dyboqF4EwV4TLgje6J0t9CACA\neIJye0YKzkAElUYt2ussAICuMW+Jj2hxEkpOjZNThAkhUAkEsQS3RuRDv2P6PD0x5JrX12IZwfUZ\nCmGrnivCHA6nPNhzaBAA8MKZsZzPjcQSiMQT3CNcDjx9YkT6eylV4SeODuG677+KKR/PzY3FE/CG\nYjMKYWUrTE46kiIskyMMAGqBIJbginA+DDgDaKowQCUQHLw4vz7h4WR8YCZF2GpQ80KYw+GUnFg8\nge4J8T790tnchXAwIt6b+GS5EnNhwofDfU5sS05sGixhMH3XmBeRWALnRrnyyZp/Kk0aNFcaIBBg\nkKvlBRGSCmH5VbdaIIhxa0RejHvDWF1jwuZGKw70zG8hPOoOwWbQZNw+tBk08IZjiPPFDIfDKRG+\ncAyf33McE94wNjVacbjfickcop4/OTSLK8IlJp6guHlTHT6zey0AYMBRumKLFXqd3AIAV0AcplFh\n1EKtElBr0WOEF8IFkbMQVgm8iMqTSW8YNWYd1tdbcXHKP6+vNeIOZVSDAdEaAeTXoMLhcDjF5Oev\nX8Qfjg/jM7vb8N33XQJKgZfPjmf9nkCyEOaKcIlpr7Pgvz60AxsarABEX2qpYP7gLoUm86WMM9mA\nVGkUb/L1Nj1Gk93znPwIZWmWA0RFOBrnHmGlUEoxkUw00aoFxBT87l48M4bDfc6CXm/UHcroDwbE\n1AgA8AR5w1yhsBsyh8NRDqUUp4bcoJTi4EUHNjRY8YWb2rGp0YoVdiN+d3Qw6/ezJl+uCJcJbHRp\nKT3CbEwqbwoDnH5xQVJp1AIQ/ZGse56TH9ma5QBArSJcEc4DTyiGSCyBarMOapUyW8nd/92B9/3n\nmzg56M779XIpwuVw7VqMnB52413/vg+PHurHZd96Ef/nj+dAKT8POBylvNE9hT/78eu4/5VuHOl3\n4vJVlQDEJuy/urwF+3scWafCsq81V84eFlRqlmUhbNCooBZIyZpOwrE4xpMjhTvHfMv+guyUrBHT\nivCIK7jsfy+FkLtZTuDxaXnAfG81Fh20KgGRPNT0XArJTMKxOCZ9YdRb5TOEAcCqF7cVF2rc81Lh\nMw8fxelhD778+EkEo3H85LUL+Mwjx0p9WBzOomF/zxQA4PvPdyIQiePK1VXS197WagcA9Exmto71\nJWMoV9gXaSFMCLmFEHKeENJNCLknw3P+khByhhBymhDym+IeZnEhhIjB9CW6mUz5xMJvfb0F7mAU\nE97lnRwxbY0QFeFGmwH+SBxeniWcN8waYcjoESaI8/g0xbBzs9qsg0Yl5LSVJBIURIxrxktnx/Na\nzI17xNdqqFBijeCFsFL6pwK4MOHHpkYrmioMeOgjl+ODO1fgD8eHcWxgfuPwOJylwoGLU5LAsrrG\nhHdsqpe+pmSnqnfSjwabPuNuZSnJ6VomhKgA3A/gJgCDAA4RQp6ilJ5JeU4bgK8AeDul1EkIqZ2v\nAy4WNoMG7hL57FixsrW5AudGvfjt4UF88vq1JTmWcsAZiECrEmBMniDMIznqDknNQRxlBHM0y6kE\ngii3RigmVRFWqwgSVGy6VQlE9vmBaByUiovcc6NePHV8GLdta1L0WqxvIJs1wpxsNPFH+HRApezr\nFke2/+iOS7G21gwAuHyVHQ8fHMCLZ8akFCEOhyMPpRQnh9y484oVuHvXapi0qrRroJJC+OKUH6uq\nTPN+rIWgRBG+AkA3pbSHUhoB8AiA22Y856MA7qeUOgGAUpq9fbAMsOpLl8cZjomq0uZmGwDge8+d\nR8/E8m2aG3aJDUIkKaWxQoAPHMkf5hHWqeVPbY0gIM6tEYqZVoS10CRHVGdThVmawwd3rsSaGhMe\nPTSg+LX6HLm3Dtli0c93SxTT0etEjUWHNTXTN2GzTg2bQQNXsHQN0xzOYmHKH0EomsAKuxFNFQZU\nJHdvGUp2qnon/VhVvXgL4SYAqVfzweRjqbQDaCeEvEEI2U8IuUXuBxFCPkYI6SCEdExMTBR2xEXC\natCUrOGEFcLNFQbctq0RAJZ1SkK/I4CVVdM3/4YK0SM5yhvm8iYcjUOvEaRFxUz4ZLn8mPSFoRII\nKo1aaBUVwmKBajNosL7emtd53T8VgEogaKzI7BE2SYowL4SVcmbYg82N1lnnRCl3BTmcxQRr7s/U\n6KbXqKBTCxkLYXcgCmcgilVV5ecPBorXLKcG0AbgOgB3AniAEDJrv4lS+lNK6Q5K6Y6ampoivXRh\nlNIjHE5uX+vUAj5x7RoA4gdluTLgCKAlRQWrtehACHhyRAEEo/GM/mAA0KiKO1nuP1+9gC/sOYax\nJbqQm/CGUWXSQhAINCqxkMqWHMEKYbNejRqLLi//f58jgMYKvaQ8y6FTC1AJBIEwt0YoIRSNo3vC\nh02NtllfK6UYwsmfUDSOp08MZ00mKJRJXxg/fLGTJ+pkYDBZCDdlWaTbspxPvcn89XJVhJUkGw8B\naEn5d3PysVQGARyglEYBXCSEdEIsjA8V5SjnAateU3JrhE4jSEkJzmVWCA+5gvjmH06judIIhz+S\nth2sUQmoMesw4ubWiHwJReMZ/cFAUhEukjXC6Y/gu386BwDY2GDF3btWF+XnlhOTvgiqzToA4jAS\nQJk1wposhL2hWM73hNE/5cdKe/YbBSEERq0KPm6NUETnmBfxBMWmRuusr9kMpbsHcPLnqWPD+NLj\nJ1Bt1uLQ127MuOtVCH+/5zhe65zAte01uHRFZdF+7lJhyCUuPpoqsyTaKCiEW8u0EFaiCB8C0EYI\naSWEaAHcAeCpGc95EqIaDEJINUSrRE8Rj7PoiBfBWEkiuqRCWK2SkhLm6lX71f4+dPTO7/jXYvLy\n2TE8d3oMP3v9IoDZvsiGCgNXhAsgGE1kVYTVKqFo1ohnTo5If++d54lrpWIyOUwDgGSNyBahxgpU\ni14jfZ9SVXjAGUzbGcmEWafmQyEUwiKbVteYZ32tlH0inPw5NigmfEz6IriYJaarEE4PewBM35s5\n6Qw5g7Do1VJTnBzZFOGLk34QUp7RaYCCQphSGgPwKQDPATgLYA+l9DQh5JuEkHcnn/YcgClCyBkA\nrwD4IqV0ar4OuhhYDWpE4gmpuWghCcemrRHMW+OagyI86QvjH588hdt/8hYii+REnpk3uGNV+iq8\npdKAzjEvEnyrKi+CkTh02QrhIijCHb0O/M9bvXjrwhSaKgzY2mxD72TxtyvLgQlvWFKENeo8rBE6\nNWqThfC4gkI4Gk/A4Y+gzqrL+VyjVgV/AdaISCyx7PKHpSQOmUi6bDduTvlxasgtbc2/0T1Z1J/N\n0mFcJZw2W85M+MLS9SwT2c6n/qkA6q16RTtjpUCRR5hS+iyltJ1SuoZS+u3kY/9EKX0q+XdKKf0C\npXQjpXQLpfSR+TzoYlBlEpXYKf/cM3xdgQi++Nvj2NuprAEwHJ1WhAExP3cuJ+ALZ8akv79xobgX\niPmiZ8KPzU1W3PeXW/H0p69GrSX9RnXjhjqMecI40l/YqNrlSiASg1mXSxGeWyF8+0/ewtd/fxqv\nnB/HZSsrsaraVHSFphyglKYpwmpBuTXCkrRGAMCEN/fOBssWZ0V3Nkw6dUHNcv/56gVccu/zeP70\naN7fu1gZcYdg1qllYxjZjZsP7il/ovEEzo148WeXNKDeqseR/uLlP6furiw3i6JSHP4Iqky5C+FM\nC+1BVxDNWWwVpWZZTpYDIL2p7AY0F777p/P47eFB/ODFzqzP+/FLXXjl/HiaRxgQJ6rN5QTc1zUh\nZfotlsixi5N+tFab8d7tzdjcNLuR5caNddBrBDx2OL/pXMudQCQOgzaz9V9dxNSIQCQuFsJVJgy7\ng1I+9lLBFYgiGqeoNouLZo0Sa0QoBkIAk1YtLe7GPLkX20yRUlQIa9UFNcuxyVBffeLksvEYD7uC\nGXOZbQYNYgmKAM9kLntGXCFE4gmsqTFjU6MVp4fzH1+eiZ6J6UW8kyvCsjj9UamfKRM2gyZj0/+Q\nM5i10a7ULNtCuDqp1hRDEe5L+iNPDbkz5nse6Xfi317oxEceOpRmjQCyf4CUcHLIjRs31EIgwNgi\n8NV6QlEMOgNZjfNmnRq3bW3Ck8eGlnWiRr4EIjGYskzumas1YnxGOsTNm+rRYNODUlE1mMnpYTfu\nfer0orS4nBv1AgDWJIcwaJPWiGwjqj2hGMxaNQSBoNqshV4jKOpynx7coc3xTMCkK6xZbsIXRp1V\nh0lfBD/dW9YtHEVjxB2S4hhnwvyOy80ushgZTGnW2tRoRfe4D8EiLWAupGT4z8WiuJRxBiKwm7Jf\nm6wGDbzh2KxrfSyewKgnlLXRrtQs20KYWSMmvXNfAU76wjBoVIjGKU4Myq9UHz04HcV8ckh8Tqo1\notCVqCsQwYAjiG0tlag26xSpT6XgUK8D9z51GtF4Ar87PIgEBd6xsS7r93z4qpUIRRP47WHlQwmW\nO/5wPOsIS/Uc49PYZ/fHd16KE/e+A/U2fdaC4m9+fgi/eLMXw4swAeRU8v+6JbljwawRsRw5wha9\nqMgTQrDCbpQGZWRjMg9rhFGbf7NcIkHR7wjgtm1NeNclDXhgb0/RColyZsQdRGMGRdiqYBoWpzwY\ndokL8KYKAzY12ZCgwLlRT1F+9oUJPwQC2E1zsyguVSilcAYiqMxVCOvVoHS6T4Ix5g0jnqBoqijP\nRjlgGRfC7IYzWQRFeMIblm6WmRTmc6MetNjFFdGBHjHdQZtUhK0G9awPj1KODYheqc1NVtRZ9WU7\nmOM7z57FL97sxdeeOIl/f7kbl62slLVEpLKp0YbLV1XiV/v7uI9PIcFoHKYs1giVIMwpK/PEoBsC\nAXZvqJV8l1JBIaOmMKVzwLH4CuETyeYcqVlOUWpEFJYUP+oKuwn9yeSCvizJGnlZI3TqvEcsj3pC\niMQSWFllxG1bGxGMxnFmpHjby+VIIkEx5Y9IXu2ZMIXLUQR7HGd+YQMd6m16KQqPJT3kiysQwT/8\n9jjGk979C+M+tNiNqLXouEdYBl84hmicwm7MXghnGrPM3juuCJchBq0KJq1qzh7haDwBZyCK9npx\n+9Qpsz2cSFB0jvlww7pa6NQChlxBaFRE8vUWovAwnjw6BItejR0r7aiz6stysEE0nkDXmLj9tKdj\nEJFYAv/39ksUfe97tzejdyqAzuT3d4978b3nzi2r4PPDfU48crBf0WfEH45JY3jl0Agka7NXLk4O\nubG21gxjSrHNCmLPjMVc6uJlPkLw55vucR/a66Zjt5RYI7yhGMz66d/Nyioj+h0B/Gp/H6793qs4\n3CcfcTjpDUOvEbK+dwyTVpX3iGUp0L7KhEuaxVlHmXavlgreUAyUImPkE/N+T/jKcxeNM82QK4Aa\niw56jQpNFQbYDJqCC+FnTo7gscOD+PnrvRh2BfHSuTFcvsqOCqOGK8IyOP1iYavEIwzMLoRZTVJv\nld+ZKQeWbSEMAFVmnaTEFArzRbbVWgCIM7lnMuAMIBiNY0ODVfLFMlsEIBblShs2IrEEBp3TCtOz\np0bxF9uaYNCqUG/TlaUifHLIDV84hm+8exMuX1WJH92xDWtkcj3l2L2+FgDwwplRhKJx3HjfXtz/\nyoVllSbx0f/uwD2/O4mnT4xkfV48QRGOJdKK1JmoBFLwIoJSipND7llKvtUgvt4sJSClcbN/ERbC\nTn8kTaFlinA2a4QvPG2NAMRCOBiN4/8mB4909Iqf2397/jz+67UL0vMmfWJMm5IhASadGoFIPC/f\nNcvTXVllRL1Nj1qLbskXwiybvSKDkiXtCnJFuOwZdoWk0eOEkDk1zL1yTkx3euRQP+596jQoBT5/\nU3vSorj4FOFAJCal1cwHzLaZyyOcySKn9PtLyTIvhLVzLoRZWH6dVfRKyinC3eOimtlWZ5Eab1ij\nHCAqPLEEzZkBHIsn8MGfHcDV330Fp4fd+NbTZ6BTCfjUDWsBALUWfbLTvbyyhM8kV+67N9Tit5+4\nCrs3ZPcGp1Jr1WNDgxUHLjokGwgAvHp+vOjHWY5M+cLSYivXYAamGJtyxKdlUzSzMeYJY8IbxiUz\nCmHpAjijEGa+PmDxFcKUUjgCEdjN0xdvZfFpMZh104UwC5BnavnxQReGXUH8+OVu/Osfz+FEckjA\nqCeUMd1gJkyZycfb2jvlh1YloMEmFhPbV1SiI4M6vVRgv59MirDNoIFGRTDFFeGyZ9wbQn1KxvaG\nBis6x7x5W+bCsTje6J7ExgYrXIEonj8zho9fs1pSmRfjgJWb7tuLnd95ad5+viNZyObyCNsyXJfY\nrntlDkW5lCzrQrjRNvfpZand3naTVlYRZiptY4Uea5KKsCBMKz8s7irX1veLZ8dx8KJ48/rwzw7i\nxbPjuHvXatQltxzYB7XcImDOjnhg0asLjk/ZvqICx/pd0uS89jozXu9aHHnJc+XE0LTqIbfISoXt\nKmRtlhMI4gXGp7FGuS3N6YUwK/xmKgHMg1dt1km7GIuFQCSOSCyR5otj1ohIVmtEukd4VdV0MopK\nIDjS58ITR6cn1P/xlJjpO+YJS+dxLuwFZKD3TwXQYjdIdqydq+0YcAQX3fuSDywBINOWLiEEVab8\ndgU9oei8qm8ceSa84TSv9wq7EaFoIm81/+BFB4LROP7h5nZc0WrH7vW1+GRSSLLoC+/VKRW+cAxD\nriD8kXjWnapMjHtCOXeW2H0nl0eYWeRmFsIOfwQVRo00or4cKd8jWwAaK/QYdgXn1IjF1Dq7SQe7\nST79YcwTBiFiQcC2d1I/LMwXmMse8djhAdRadPjCTe1Swf03V62Uvs4+qMzTUy6cG/ViQ7214Nnw\nl66ohDccw8MHB7CmxoSr19bg/Jh3WfiETwy4QYh4M3fkWOAw32i2Zjm1qvD4tJODLggE2NiQXgir\nVQLMOrWMN0wsMLY228o2zSQT7LxOVUGUWCO8oRisKdaI1AaR27c3Y9QTwm87BrC5yYpLV1Sgo9cB\nSilG3EHFHjq2pZ9Pf0PvVAArU4rynWuqAGBJLyhzKcIA2xVU/nu85N7nceuP9s352DjKicTEPpwa\n8/T5wYYzDOWZm//86THo1AKuXF2NRz66Ez+763LJpmjVaxCMxhfNdFYg/fydOa1VDn84hnOjHlBK\n8esDfbjiOy/lzOqXroUFNss5/Lmj10rNMi+EDQhFE7L5p0phqkOlUYNKo1b25jTuCaHarINGJaA+\nuf2ZerIpKYQppdjf48A7NtXhjstbYNWr8Z33bEnzv1WaxA/iXP4/88GFCR/a6pR5guXYudoOQLzo\n3bypHuvrLQhFE4tuu70QTg65sKbGjJZKY9EU4ULj004OudFWa5H9+eK2YrqaMu4JQasWsLbOjHFv\naFElf0i+tpTziykamawRkVgC4VgizRqhSVFB3ru9CYBYlF61phqXr7Lj+IAbE94wQtGEdG3IxbQi\nrOw8jycoeif9aer0ujoL1taa8bPXLy65QSgMdkOuyFIIV+fRJ8KKrkHn4ktAWcyw96c2xRrRXCla\njvLZ0RjzhLCnYwB/dkkjDFpV2q4sAMnbX0zFP56g2HNoYM4WzEyk/v/PjuRuHrzvhU7c8sN92P6t\nF/CPT54CAFzMkmYDiDWOSiBpvQ9yGLUqqAUy2xrhD0txteXKsi+EgXQvY764g1EQAlj0GlRlVIRD\nqEuexMyjl4pRgTViyh+BLxzDmhozaq16HPund+Cv37Yi7Tn2MrRGhGNxuAJRxdu+cjRXGvG92y/B\n1Wur8akb1qK9XmxMPD/qxZAriA///CB+9GJXsQ65bKCU4vigG5c02VBp0sKRo5GDFcLZFWGhoMly\nrFFupi2CYdGrZ1kj2Oe+zqJHNE4XVSMKKzJTPcIaVXZrBBtykemGcemKSunvN6yvxXXtNYjEE/jl\nW70AoLgQrkoek1Jva9e4F8FoHFuardJjhBB8+oa16Br34Y6f7gelFJRS7OuakOxXix12Q7bmKoRz\neO8Zr5xbHn0J5cZ48v2pSf1D0Q4AACAASURBVGlcZTst+SxKfvxyFxKU4nM3tsl+nX1OimmP+Prv\nT+FLj5/Ao4fmJwufeZoFAnSOeXM+/41uUUF2BqJorTJBIMiZQOMIRFBp1MxaOMyEECLrs3b6o2Wv\nCGcv8Zc4zLM65ApmvMHnwh2MwqJTQyUQVFtERTieoJIXDxC3iFkjjNzNzqRAEe6dnI4/AiD7oWTq\nVTkpwkwhz5TlqZT372jB+3e0ABA9wgIRM5R/faAP+7omsbdzAp+4bnVaGsdiZ8QdEpvTmm04NuCS\nPgOZ8CcXUsZszXIFKsKjnhAmfREpL3smVoNG1hpRZ9FLi6AxT6jsL4gMOV+cNoc1gilJqR5hAHjy\nk2+HOxiFVi3gx3deCrNejZ2rq5BIULTYDbj/FTE9Qqk1gm1RKlWEj/WLDXnbWirTHr9tWxMmfRF8\n6+kzeOnsOGxGDT70s4MAgCNfv2nRvFeZcAej0GsE6DWZz4dqsxaT/ggopTmtW+zzXc5NP0sR1iSc\neg8x69SoNGoUK8LuQBSPHhrAX+5oQYtdfrDDdAxkcRbskVgCTx0bBoB5i2XzJK1Y1WYdLua4P7gD\nUZwf8+LzN7Zj+8oKbF9RiXf9+76cAoXTH8lpi2DYZO4DU/4Itq+sUPT9pWJZK8KsEJ5Lw4grEJHs\nCfVWPWIJOkupGfeGUJu8yVll1CK21Zxt0lNvMv5oVZaxxBWSR7h8CmF2EVMyKEApRq0aV66pwk9e\nu4B9XZPY2iKeZCNzUPbLjVA0ju8/dx4A8Pa11ag0abO+r6FoHB956BAAZM2iVQsCKEXe/moWtZVp\nwVgjs8U86AqgzqaXdkPKMeM6E3Ie4VzWCKYkmWec49taKnBtew0A4M+3NuL6dWIkoCAQfPmW9QCA\nWosOmxqVLcY1KgEVRo1ij/CxARdsBg1WVc0uAD585UpY9Wq8fH4cL6convu6JhT97HLGFYhk9QcD\n4nUpEkvAqyCXmb3voeji8ZAuBeQKYUCMP1Uq+rx8fgzROJXEFDnYTs5Mi1ehHOl3SrtEuRJ/CsUd\njMJm1GBVtQk9E9kL4de7J0GpaDXc1VYDk06NCmPuaXqOPAphy4xCOJGgisYzl5plXQhXGDWoNGpw\nIccHKBuuYFTqSq5P2h5Ss3yjcbGzlRUDcqoDs0b4s1gjeif9UAlEahKQQ6sWYNGpczZVLSTTqRrF\nK4QB4Latot9yV1s1vnzzOgDAcJ6NE+WKLxzDe/7jTfzu6BB2tVWjrc4Cu1ELbzg2q5HjW0+fwd2/\n7Ejbts226FAnt/fztUecGnJDJRBsbLDKfr3epseIa9oHPOQKYsARxPYVlZIiPD5PN4P5YNIXgVYl\npC1cmTUiU/wcK4RzeelS+bNLGvE/f3sFnv3srqze7pmICTXKfp/HBlzY2lIhe+3RqASsq7ega8yL\n185P4IpVdlSZtEvCBuAORlFhyH4DrraIX1dij2CLx2A0vwxnztzINHXRpFPDF87tbw9F4/jV/n7U\nWnSzoh9TmbZGFEcR3t8zBULEHcz5GtriDkZhM2jQWm1C75Q/7XO5v2cKN933Gu57oRMA8PtjQ6i1\n6LBjlV16TqVRk9NK6QpEpf6jXMy0RnhCUcQTFHZTce//xWZZWyMIIVhba0b3eG5vTSZcgaikOrCt\nzRF3CJc0i19PzRlmPP6/r4QppaFGSbPcmCeEmmTDXTbsZm1ZWSMyrebnyu2XNaO1xoTtKyqlEY6D\nS6QQfvLoEM6OePB3163Bh69cBUBUPwCx8YD5zBMJip+9fhEA8NYF0fv18t9fm70QTlpqYnEKXR5n\n/4lBN9pqzRm3mRtsegSjcXiCMdiMGsmLdvXaaul45ksVmQ/GPCHUWtMHXGiSOcKZusrZDdSqz2/r\nfFdbTd7HJ9ecKIc/HEPnmBfv2FSf8TntdRb8+kA/AOBLt6xDU6UBr3VOIJGgOX2B5UzqtTkTqUM1\nVud4G1IXQIFoPK0pkjN/TPnCsOrV0KrT731mXe4Ji4kExRf2HMPhPifu+8utWT/P1gwDIQqlc8yL\nFXYjWqtNOW0LhZJaCIeiCYx6QuibCuBtrXb84o1edI37EDwyiL99eytePT+BD1+5Ms22WWnUSlNb\nM+EIRLDdpMzaYDNo0J/SfMfsW7xZrsxZW2tG17hPUrL6pwJ5nQjsgwhM+39HU7KJ2XZwXUrH62Ur\n7VhfP62sGRVYI5yBSM5Aa0D8YJdjIVzsE0EQCC5fZYdKIKi36UHI9ExzRiJB8eKZsXlPK/DlOe42\nF6+cG0eL3YAv3rxO+kyxhcR4SgzZsHv6/+uPxNFeZ8bqHBP72EUwH58wpRSnhtwZ/cHA9Gd/xCMe\n05lhD8w6NdrrzDBoVdCphbwGQJQasdEv3bMrCCTpsc5hjViAAkmnFhTFPJ0cciNBgUtbMt/I2uss\n0t+vba/Bdetq4PBH0jKsFyNs2zgbVSZWCOdepKV6w/Mdcc0pnMkZEx4ZJq065/vww5e68OzJUXz1\nnevx3u3NWZ9bbGtE55gP7XUW1Fh082uNMGiwOmmZ/K/XLuDOB/bjp/t68HJy6NSQK4gnjg4iEk/g\ntm1Nad+fyxpBKc3TI5weozkdL8sL4bJmba0FrkAUk74I9nQM4JrvvYJ7nzqt+PvdKdaIKpMWGhVJ\ns0aw/NRaS+ZGGCXWCGcgqqhJI1OWcamY9IVh0auzNqzMFa1aQK1FNytT8id7L+Du/+7Ai2fnb5v3\n9LAbm//5OTxzYqQo26WxeAJvXpjC9etq09TIWlYIp1xQu5ITC1kj5oeS6nE2lGThzmTYHcKUP4JL\nsjSUsmNgA2omfWIAPvs/VBqze5zLjVFPSLZ5Ta0iGa0RuVIjiolOrUI4lntbmH1GNmSwtADAFa12\nqAWCFXYjNjZYcU1bDQhZ/CkJqSJFJpg1QkkCR+risRSDF14+N4ab7ntt2RXhU76wlJSSilmnznrP\npJTiNwf6cOOGOnx01+qcr2PWqkFIfhMbMxGJJdA76Ud7nRk1Zj2cgei85BOzzzjrHfrTaXFAzwN7\nexCJJXDXVatAKXDvH85gXZ0Fm5vSrwOVRg38kczZycPuEGIJigaFw7BsBg08oZgkPvFCeJGwrUW8\nuR/qdeDnyW3m50+PKSpqEgkqNsslfWiCQFBn1acpk9OKcOZCWK8RQIgCRVjBqkwsOMpHeZvKsJov\nNk0Vhlke4VeTM+ULmbijlKdPjAAAPvmbI/jH35+a88+7OOlHMBrHpSvSFbxpn+30Iqs7uaX10w/t\nwD//+UZ84Ir0OD05mCKcT7PcyWSj3OYsijCza7DdkJkh6hVGDVyLSRF2h9JySxkaVWYlllkjZjbL\nzQc6tYCwghvrgCMAXXKhmIkNDVac/ubNeO5z14AQgkqTFttaKvBq5+JumBM9wtkLYbtRC0KACQWN\nh9ESK8KfffgYusZ9OHBxasFfu5RM+SKScp+KUaeCP4tHeMgVxKQvgmvbqxUNcxIEgtYqk6I83lz0\nTfkRS1C01Vqk3bz5yBJ2B6OwGjSot+qh1wiS8Dblj6CpwoD3pajg3739klm/h4rkNdoVlP/8n0v+\nLjbUW2S/PhObQYN4gsKfrGV4IbxI2NpcAbNOjV+82Ytzo16sr7fAF47hfIZMvofeuIjLv/0i4gkK\nTyiKBE0f4dlWa07L8xvzhKASSFZrACEERo0qq0fYFYhmHBWait2kKStrhNLjniuNFYZZivC5UfEk\nVlIwFMqLZ8akv//mQP+cp92dGxU/O+vq0lfu1Wbxhp1qjege96HarMWWZhs+8vZWRX5OqeErn0J4\nyAW1QLKqijUWHQQyrQiLN68ZhXAZ7VRkwxeOwR+JyyrCOrWASKbUiHAMWrWwIBF+Oo1K0ee6b8qP\nFrsx52dDp1alNetd116LE4OuRWVnSSUSSyAQiedUhNUqAXajFhPe3IkmqRMZF7oQDkXjkvr51oVl\nVgj7I7KKsNgsl/l9OD4gLuC3ZrEFzeRtq+042OuY83W8L5nytLLKOGu3rFiEklPwbAYx4zd1YA4A\n7N5Qi9U14mO72qqxTeb3UGNmzaKzr80XJnz42192AICU3Z+LmWOWeSG8SFCrBFzbXoODFx0walX4\n1/duATAdPD2Tb/zhDCa8YRwfdEkWiNRs4A0NVnSP+yTVaMwTRq1Fl/NGZNSpMw7UYMqzIkXYpEUw\nGs+qLi8k+USvzIWmSgNGXNNz0xMJCk9y+1JJNFIhjLpD6Br34avvXI8f/NVWAKJVYi6cG/VALRCs\nqU2/qKlVAqpM2hnWCC/W5PAEz0SVbPiK5zFm+eSQB211lqz2Fo1KQI1Fh9Gkb3nmzavSqJWmMJY7\nTNWW28Ux6TL7EmeOV55PdGoBYQUT4fodQazIkJuajXX1FlAqKsqLEWmqnIJFeFOlQdFghjRrxAIX\nwj0TfrCXP5LMhV4OxOIJOAMRqVk4FbNWjUgskTHO8PSwG2qBpPXj5GLn6ip4Q7E5X8cHkpGsLXYj\nGipYIVzcZu6Zo49bZ0SrXrayEiadGvu+dD0euuty2Z9Rm5LxPpMH912U/q60AVgas5y81k/5IjBp\nVfNqjSwGy74QBoBvv2czPn7Najx01+W4dEUlVleb8KbMqjvVLrG3c0K6YaYqR+sbrIglKLqT3jy5\nphs5jNrMirA3FEOCQlGzHBsAUC4+YaUF/FxprjAgEk9I20+pwwZ88+Tnm05GqMHO1VUAxKiquXBu\nRCxu5VTFGoteUq4opegaz3909bQirEwlp5Ti5KAra+wQo95mwIg7JGVHpm5nVhg1i2ayHLuJyUUV\nmrTqjJ8nbyi2YEkCSqwRlFIMOAIFFcKNyZv3Yo0kdCe3erNNlWO0VBoVFsKls0awrPuVVcay2vGb\nb5yBKCgVd8RmwpKXMr0X/Y4AmioNs9ImsnH12moIBHPuK+l3BGDUqlBl0qZMsC3uuTQuJVKJ19mP\nX7sGn909PTVve3KSZYvdKGWgz6QuSyF8uE+cMPn9929VfExSISwpwuG06ZzlCi+EIXZOfuWdG/C2\nZDFz1doqHOiZmrXS7OhzSn8/1OuQ9f+yzvr9PWIhPewKSoM7smHQZPY7sVxgJc1yrFgul4ul0ia/\nuSKN3ExebFJPbF+4+AXYuCeE7z9/HvVWPdbXW1Bn0UOjInPe/jo36sW6DNtQtRaddPGb8IbhDcWw\nNm9FOD+P8JArCGcgis0KJi822vQYcYfgDrLsyFRrhNidPN8JHsWgLxl1tLJq9vAasz7zdqwvFJ01\nVW6+EJvlshfCzkAUvnAs4yStbLCbd7G3cxeKaUU490242W7AkDOIcCyOH7zQiSePDskWV7E4lRTm\nTJ+BcCyOvZ0TRS96WKG+ucm2aCxGxYBlZcv1mbBFZ6b3YsAZREtlfp/9KrMOl62sxJ9Oza35ecAh\nvjYhBFa9BhadGsNFHvjE7nGsEX9bSwU+f1M7Hv3YTvzNlSuzzhxgsLHVozMK4SlfGJ1jPtxz63rc\nfln2tI1UrDML4UC07DOEAV4Iy3L12mr4I3EcT1H3KKX4yu9OoKnCgHduqcfpYQ9G3bMzglurTdjS\nZMOejgEkEhRDrqCkrmTDpFMjGJU/oZ2B9C2QbLDioxwU4VA0jmA0rkjJnivsxs0aFVMj7Oajw/sP\nJ0Yw4g7hvz50GQSBQBAIai36tNfNRjASx7+/1IVQyva2JxTFkCuI9Q1ZCuGkR/hs0kvcVqfMu8Vg\nqRFKO5hZo5wyRVj8/0vZkWnWCA1iKU0U5UyfIwCTViWrQlmy+BK9odiCJEYAgE4j5EyN6E/aGgpR\nhKtMWmjVwqJVhJkNJ5dHGBAV4Ug8gQf29uBHL3Xhc48ew85/fQn3vdCJ9/zHG3hgbw8AsVlOur5m\naEh+9NAAPvzzg/jAgwekRd+gMzDnRJlBZxBGrQqrq01wB6PLZqAHm54o12MzrQjLnwcDjkBBi8A7\nLl+BzjEf9nQM5P29mV67oUKP44Ouor5v46wQntHU+7bVVfjGbZsVNQhq1QKqzVqpyY4xkLyP5iu0\nzKw/HP4w7ItgJDkvhGXYuboKhABvdE/bI4ZcQVyY8OOju1px5eoquAJRHOl3otqsnbX18qErV+Lc\nqBf3v9KNcCwhFWnZyGaNYKurXJmYwHSxzMz6pYSdDAvRLFc/Y3oZW+FqVGRerBH7uiawusaU1ojR\nYFNeCL98bhz3vdCJNy9Me9HPJ4vbDRk8bbVWHSZ8YSQSFEf7nSAEWSPN5GCFgVK/7vkxLwhBRpU6\nlQabHr5wDL1JRTXdGlF+478z0TcVwIoqk+yNJJdHeCGtEdE4zXpjnUshTAhBk0wD6mJBUoQVFMJM\nOfv+851YX2/Bno9fia3NFfj3l7pwtN+Fbz97Fr2TYgqAQaOCzaDJONWP7QRenPTj1JAHv3yzF1d/\n9xXc/pM357QbMugMoLnSgAqjFglamvi2UsCsbnIeYZNOtI/JLUz94Rgc/gha7Mpiv1J57/YmtNgN\n2Ncl3yeUC0opBpyBtNdurjTiaL8LD77eU9DPlGPME0424s9Nca216KWimsEWwEpql1TsM3akHb4I\nV4QXKxVGLTY32tIa5g4nbRE7VtmxKamOvdY5Iev/vX17M3autuPfkqMNlXyYDBoVAhlWtuyip6QR\np7XahA0NVvz45a6MTQQLBVNNFsIjbDNooFERKbh8zBOCQMTfR7EbW+IJigM9Dly9tjrt8XqbftYW\nUya6ktMMBxzThUZXMg4tk++31qJHPEEx5Y/gSL8L7bWWvLfimcqpdDzvqDuEKpNOUbMDi1A72Ct6\ny5pStuamc5DLe6s9kaDoHPNiZYbiMas1IhxbUGsEgIwJFsB0o1shxQAgLi4XqzUiH0X40pZK6e+f\nvH4trmi145f/6wo8/NGdUhPshQkfYgkqNq2atZJSmQqlFB29Tly3rgYaFcFDb17Et589C0BscLsw\nkX2CVzb6HQE0Vxqlwj5T3NVSg/2e5XZnzFk8wlKzWp7WCEBcBDbYDAWPRZ7yRxCIxNMWoPfcuh4A\nck5xywc2bVY1x+mPdVbdrPOcFcJKbJ2p6DUqmHVqTPrCoJRmTPwoN3ghnIGr26pxpN8p3fSO9rtg\n0qqwvt6CzY02GJKFwQ3ra2d9ryAQ/PJ/XSH9u9GW+8Nk0qkRyGCN8EkTq3Jf1FUCwYevXIkxTzgt\nYaAUuPKwdMwVQghqzDqp0BrzhFBt1qHCoC26IjzoDCAYjWNTY7pyKxYOQUXKDxt00J/SlT/sCkIl\nEKmgnAkrJoddQRztc2L7SuWxQAy2OlfqIR/1hFBvU7aiZ1E9r50X82dTLUH18xQhVGz+dHoUg84g\n3rGpTvbrFp06oxrnCUUXzhqR3IUKRzMXwv1TAVSbddLAnnwx69VZIx3LGaYIK2mWsxk1+Nnf7MDt\nlzXjnVsaAIjX0SvXVOGSZvEc84VjiMUT0AgE1SadbCbssDuEcW8YN6yvxbXtNfjdkSFEYgk88OEd\nAICDF52zvkcJ8QRFz6Qfa2vNqDTlt6Oz2Jnyh6EWiGxqQbZmuf6pwndDANE7W2jur7QATSnC2+ss\nuHRFRVGTI8a84bSJtYWyssqE3il/2u7SsCsEk1YFqyH/a4fdJE63DUTiCMcSZR+dBvBCOCNXr61G\nLEFxMBle3jvlR2uNCWqVAK1awEMfuRzv2tKAT1y7Rvb7dWoVHvvElbhydRXW1ub22Ri0qoyRZ6zZ\nS2lQ/7SPrbSqAVtRy63m54Maq15ShEc9YdTb9FkVvEJhiSAz39d6mx6haELRiE42DCM1nmrYHUSt\nJfMKn3nBnjg6BG84ht3r5Yu1bFQYNBBIHoWwO4R6qzJVYE2NGQIR7RS1Fl1a8kWDNX3gRrmyt3MC\ndpN21ihShkmnRlgmsikSS8Abii3YRV+nSRbCWXzCF6f8WFlVWCEAsGSKxVsIW/RqxWrZ7g11+P77\nt856viVZbHlDMcTiFGoVERVhmfPnzLCYW765yYbbL2sBANxxeQtu3FCLGosOh5I7JfnSN+VHJJZA\nW60ZNkP59IDMZD4aYad84mAeufhRZrmTS6NhHtdCPMIAMqr+SpAsSTPOvQZbcXdYBh2BvK0Lcqyt\nNSMQiWMkZTdz2BVEY4VBkc94JqwQXiwZwoDCQpgQcgsh5DwhpJsQco/M1+8ihEwQQo4l/9xd/ENd\nWC5bWQmdWpB8QsOuYJqyu3N1Fe7/wHZpVSrHjlV2PPyxnWlB9ZkwaTOnRvhCMRAiPkcJc2mYu/+V\nbjx6qD/v75ODdTo3KeheLQY15umZ7mNuMbbOnCN0vRBYITwzw5cpuSOe7Kv+WDyBnsnZivCIKySF\nr8vBuoN/faAPZp0au9qrMz43E4JAUGmUv5HLkY8irNeoJAVmZsey1aCGXiOUfSE86YtkXYxk2o51\nyDQIzidskZEpOYJSinMjHkXe7myvkU1xLmfcweIM8mHigzcUQzSRgEayRsxWC88Me0AIsL7egls2\n1+PAV3fj/7xPnOa1pcmWNrFswBHAU8eH4QnlVnY7JcuURfo/ldugk1+8cRGtX3lWmq5YLCZ98hnC\nQKofdfZ7MZBseC00sajarIM7WNhYZHbfm3kNrLcaMOoOFWXBEIrG0TvlR5sCkS0XTNBh9zUAGHQF\nFI9VnkmVSVxESIXwAuwIz5WchTAhRAXgfgC3AtgI4E5CyEaZpz5KKd2W/PNgkY9zwdFrVLii1Y43\nuidBKcWQM1iU1VcmDFo1gtG4bPOLNyw24ShdnTErQr4RaokExU9eu4A/HB/J6/syMeQKotKoKXhr\nNl9qrboURTiEequoCBf74swmus2MZlK6/d87FUA0LsaLDTgC0oVxxB3MevGpsehACBCNU2xtsRU8\nwcxukr+RzyQUjcMViMpOWMsES7GYae8ghKDeqtxDXSoc/nDWYja1MEpl0pc55mk+kKwRGRTbYXcI\nnlBM8WhU2dfQKBvjXI64AhFF/uBcGDQqqAQCXzgqKsICQbVZB2cgOmt0+5kRN1qrTNL1LrV/ZH29\nJW3Q0hf2HMNnHj6Kn76Wu3mKNdG21Zqla3u5WSN+8GIXgOIf15Q/nHFHUadWwaJTyy7qWWpDIYom\nMH0eK+2lSCWTJanBpkcgEpcGPc2Fi5PigJW1eaYGycEK4a4xL549OYLb/t/rODXkwfoCrx3ijkl4\nuhBeIh7hKwB0U0p7KKURAI8AuG1+D6s8ePvaanSO+XBhwg9/JK4ol69QjEm1NyRzY/OGYtIWnRLY\nKjhfa8TFKT+8oVjRmsuGnMEFU4MBURF2BCLwhqJwB6Oot+mzejoL5dyoF+0yFyBWCI/lKIS7k41y\n17XXwB+Jw+EX83VH3CE0ZlGE9RqVFGcj9/pKYVtXuZAGxijwuDM+d2Mbrmi14+bN9bO+Vp9Hqkap\ncPizdzmz89AfKY9COJSi2E54w/jRi10YdYdwLqk+ZhuLreQ1CrVGhKLxOQ+XmQvuYBQVhrnfgAkh\n4q5SKIZoPAGVIEgK5cxzqHPMl1GBZ4OWLkz40D3uw6Fe0S+spOntjQuT2NhghUmnhs2ggVogZbeg\nZAp1tubNXPzP/j7c/0p32mOTvrBsdBrDnrQw9E8F8OXHTkiWJTG1oXBbEFsMF2KP6HcEZBtUizlh\nrnNMvIe05zlQSY4qkxaNNj2ePz2Gv/v1ERxPRmbO7IFRit2kg8MfmU78WCLWiCYAqYF6g8nHZvI+\nQsgJQshjhJCWohxdidmxUuwmfvakqJDOpyLMbA9y9ghfKKbYHwyIndKEiGHW+XBiULxxFUtBHVI4\nTKRYNFboQen0dDdmjQjHEgVtcckRjSdwftSLzTK5urVJxTaXIszSIa5LNloOOINw+CMIxxIZG+UY\n7AK9bg6FcJVZi1FPKGempTRCPA9FeFOjDXs+fiXevbVx1tfW1JhxbtRb1r7TKX8k64WbWaFmNmBO\nZulunw90mnRrRCJBccdP38IPXuzEnQ/sx5F+J1QCwfo5FcK5h3Zk4iMPHcJf3P+GlLYjR/9UAN9+\n5sy8fB5cwWhRFGFAtMN4QzHEExQaFZGaVlOzV6PxBPodAalhdCYbk9ngh/uc2NMxALVAoNcIOZsR\nvaEojvSJSRSA2MS3osqIixP+YvzXik6mPhclfP3JU/jec+fTHpvKYo0AxCLL4Y/gS48fx6MdAzja\n70pOVCxstDiDLWgLSY4YcMpPc1xdLRatTOGfCxcm/FIq0lwhhGD3hjop7YdRaCFca9EhGqc4nfTM\nK5msW2qK1Sz3BwCrKKWXAHgBwC/lnkQI+RghpIMQ0jExMVGkl54/NjXaoBIInjo+DCD/KJF8MCS3\nUeQuJPnGMqlVAmwGTd6K8PEBcSVYaMqCKxDBm8nIuURCtJM0VRR+McoXNgnsQI94Qtdb9VIXf7FG\nonaN+RCJJ2QvEhqVgBqzLqfq2TXuQ3OlQdp66ncEpOI51/AVNrlwLhf5q9fWYMARxA9e7Mz6PDa5\nqD6LSp0PuzfUwheOYX9PYU1D8w1reMtWCLOL+gP7etLO1VJbI44PunBhwo9NjVZcnPTj8cNDuGxF\n5ZxyjbVqAZFYIm9P48VJP95K5un+en+f7HMisQSu+d4reGDfRRzpK65yTCmFOxBVlLuuBIteDW84\nJsWnsftAasbygCOAeIKitVpeoVtTY8a6Ogv+5Zkz2NMxgBs31KGl0pg2UEeOxw4PIpaguGnjdGPs\n6mozLk6WTyGcuqAOx+TtfbmYkEk4CkRiCETiWa1K9mSCRzQ+/ZqTvgiC0Tha5rAbyXZVPXl6saPx\nBIZd8hPt2uvM0GsE6T47F/qm/GiwGQq2x83kz5PCxfu2N+O779uC9jpzxs9yLti9aX/PFKrNyqI3\nS42SQngIQKrC25x8TIJSOkUpZZ/kBwFcJveDKKU/pZTuoJTuqKmpKeR4FxSDVoV1daK3S6cWMk78\nKgZMEZaLUGMe4XywG7XSaGalHJcU4cKKxrt/2YG/fvAAJn1hHB1wIhiNY2tLfgMf5gJbHbNQ+3qb\nDmZ99pGo+cJU802NNeG/AAAAIABJREFU8v+veps+rftWjq5xH9pqzdLFciClEM6lCP/Dzetw/19v\nx5VrqvI9dIk7r2jBX+1owY9f7s7ayT7iLm4hfNWaaph1avx6fx+i8UTZTcdizaXZPG3r6i34x3dt\nwPNnxvDlx09Ij0/5wtBrBMniNN+wQvipY8O48l9fwnv+402oBYJP37AWgKjmX7d+btfY6WI7P1X4\naL+oAl/Rasfvjg7hwX09UjGdSFD88s1e/CqlQE5tIpsrsXgCdz10CFP+CIxFugFb9NPWCI1ApJ3B\n1Kl7vVNiYZpJoSOE4O5drQhFEzBp1fjM7jYYsgxRAsSC/sF9F3FFqx2XrpjOOl5dY8LFKb/iMenz\nTWpM53Onx7D6q8+iayw/1TN154Dt3kkZwlmsStVmURFOJD9fwWh8OkN4DmIB24FV4ud99fw4nj89\nCkBseE5QeaFCrRKwqdEm3UPmQt9UAKuqiycyXdFqx9lv3oJ/+8ut+KvLV+D5z19bcD4x+72fG/XO\nq520mCgphA8BaCOEtBJCtADuAPBU6hMIIQ0p/3w3gLPFO8TSwvJEzTp10VZfchiyWCO8oWhe1ghA\njJbJRxGOxBI4PeyBSiAIRuN5D+OglKIjeTHr6HXimROj0KgIrpfJWZ4vai06GDQq6TiaKozSAiJT\ncX/vU6fxzAnlzYFvXhBXuWsybIGusBvRneUmEE/6BNvqLDBoVaix6NA/FZB8Y9lSIwBxu/pdlzQU\n3AQCiDflf373RujUQtb/+6g7BLNOXbRpaXqNCp+4djWePzOGtq/9EV987ETub1pAlHra7t61Gndf\n3YpnTo5IqvmYJ4xqs25O70s+sGvRI4cGpAXLnVeswPaUgun6dXM791ghnK/v82i/C2adGt949yYA\nwL88c1YqdI70O/HPT53GN58+gxa7AXaTtqiF8KMdA3itU9xtLFaTjkWvgZc1y6kIKo0aGDSqtEK4\nJ2lVWJ1lq/r9O1pw+hs3Y++XrsfGRisMmsyRmYC4YB5yBfHeS9OdiK3VJkRiibIZf52at/vUMXH3\n9OVz43n9jFND0yopa1CTG9U+E9bvwBbVnmBUiqScy66ZJZnZn2t3lFKKux46hI/9z2FM+cLonhCv\n/TOj0xg7Vlbi+KCr4IxiRt+UHyvsc7dFpKIk3UoJqf7ohewRmgs5C2FKaQzApwA8B7HA3UMpPU0I\n+SYh5N3Jp32GEHKaEHIcwGcA3DVfB7zQfOSqVmhUBJ+7sW1eX8cirUBnb8X48myWA8Qg+XxU0JND\nbkRiCVyaHBmcr5WgKyV65dFD/fjVgT7csrlBNgh9viCESLmpNRYdDFqV9HuV8z3H4gn84s1efPI3\nRxT9fEop3rwwibevrcpY8OxYWYlhdyjjaNp+R0DKBAXEi3W/I4BhVwgaFVmwrXWjVo1dbTV44cxY\nxq3vMU+oaGow42PXrMGXblkHi16Nx48M4kh/YUMG5gPm883mSWR8cOdKAMB9z4v2klPDbqzPMBp7\nPkgd6773i9fjO+/Zgq+9awNqLDpY9GrUW/UFd30zJB9ynhFqRwec2Npiw4YGK/7+pnYA05O+9iaL\n1CtW2fFfH9yBTY1WnB0tXiH8+6PDWFdnwdOfvhofuaq1KD+TNcvFEgmoVQIIIWis0GM4penp6IAL\n9VY9KnMsoky66Wxjg1aV1RrBfle72tOVfdYoe64IXtNikFrUUYjXkp48PcypiyGmBE9lGa/MqLfp\nEUtQSZV2pxTCzQVMlWPoNYKUFpKN1Pfghy924ZGDA9CqBGxtlh929P4dzYjGKR47PFjwsbmDUTgD\n0TllhM8nRq1aEhOWkiIMSumzlNJ2SukaSum3k4/9E6X0qeTfv0Ip3UQp3UopvZ5Sem4+D3ohsRk1\nOP+tW/GhK1fN6+uw7QQ2EScVXwHWCJNWnVcx+8yJEWhVAm5NTlbK1x7RkeyCXmE34pXzE6CU4p/+\nTC5lb37ZmGwOYv4w9nuTWxQMu/LrvJ7whjHpi6SpbjPZscoOADh0Ud5ywLp9WWRNS6UBA05REa6z\n6mWD4+eLq9dWYcgVTGv6SYVF0BUTrVrA3123Fvu/shsaFcFzp0aL+vPnQl9yezvTeOVUVlaZ8NFd\nq/FoxwCePTmCngk/Ll2R/6S/QtGlFMIrqoz467etgF6jAiEEt1/WjLvevmrO6nSuiDY5gpE4zo54\npbHFd+9aDUBMkAGANy5M4dIVFdjziSuxsdGKNTVmXJzwFyVbddIXxqE+B27dUo/NTbaiKVxsKE8s\nIcanAWLj9KkhDz71myP40M8O4OWz43jbanteP9egyW6N+NOpUbTXmWf1pmxosIAQ4PTwtIo67g3h\niaOFF1dzITU9g11LDlycyus9PTvikZREVlhnG6/MYFYUtiviCUUx4Aii2qyb0/ufmhaSCU8oih++\n2AmVQNBeZ8b/7O/D82fGsKramPG119ZasK2lAn88WXhEaTEU7/mmLZlm0VY7f3bSYsInyylgIYqT\nGrMOJq1qVhNEOBZHIBLPOxzemMN/lgqlFH86NYJr2mvQlGzWUhL0nsqRfifsJi3+5S82AwDesake\nNZaFUTdTuWyVeANml2BmKZErhPsc079rJRdtpjpk64Ld0GCFUauSfJIzOTbggkZFJPVwhd2IYVcQ\n/Y6AolHcxWRLs+hzPjkk37wx4iq+Isww6dS4fJVd2sYuB3om/DAl7SpK+NyNbWitNuHvfi3uKGxr\nWbhCmO20fCipTKfyz3++KePEy3woxCN8csiNeIJKiwKDVoVqs1baIeke96U1mq6wG6UIwbnS0esA\npcA17cXtP7EZNHAFoojGElAL4u/kqjXV6HcE8PSJEezrmkQwGscVrXkWwloVghkU4b4pPzr6nPiL\nS2cHNBm1arRWm6RJdgDwv391BJ9/9HjGnaj5RC5irHcqgK8+cRJ/8/OD2PEvL+DZkyMYcARwz+Mn\n0DPhS3uu0x/BsDuEq9fWpP28ST+zKmU+H2d6sj3BWDK1Ye7XUtYkmYkPPngAz50ew4d2rsTXk6KP\nXiPgUzdk3z2+aWMdjg+68aXHjuP3x4ayPlcOZsfKZaMrJT+/63K88PlrZtl6yhVeCJcJhBC01phm\nFcIsoHzm8IZcmHTKFeF+RwDD7hCuXVcjpVPkkxyRSFAcuDiF7SsqsKutGv/5ge34znu25HW8xYKp\ntWzpYskwAAEQL9YMJTE57DnZCiWVQLC5ySZlMc6ko9eBTY3TalWL3YgEFX2VmaKX5osNDVYIRL4Q\nDkXjGPOGZLufi8WuthqcG/UqGu6xEFycFMeoK1VS9RoV/uEd66R/X7Yy805BsbEZNXjjnhskH+58\nIE2vy8MawRaAqYuCpgoDBp1BuANivvfKFG8j297tc8zeCcuXI/0uaFVCwbFPmai16BBLUPgjcWhU\n4mfjAztXoN6qx8euWY2HP7oTf39Te8ax3JnI5hF+4ugQCAH+IsPP3NhgxZkUOwHz2J7McN2ZTyZn\nDJ143/ZmNFca8PDBAXSP+2A1aPDF3x7Hd/90Do8cGsCnHz6a9nxmj7pxg+hpZx5hdzAKrVrIquw2\n2gxpNiFPKJrM8Z37dSubIuwORHFi0I1Lmm348i3rsautBj3feSfOfetW2ejIVN65pQFatYA9HYP4\n7CPHcCDZ3K2U0SKn+cwHRq0abXWWBd3hnAu8EC4jVlWZpO5jButkr8yzEM6mNsyExY3tbLVnLRwz\n8fK5cQw4gvjzrY0ghODWLQ1Fy/DMl3V1Fnxmdxu+9/6tAFKaHmQWBf0pv+s+GUvKTFjET20OxXBr\nsw1nRjyzsou/9sRJHOp1SvnUQPr21lzG4RaCUavGmhozTssUwkOuICiFbDB8sdiRVO+P9Jdu8EIq\nPZO+vCODbt1cj8/ubsOzn9m14DFBTRWGeb3R6DT5WyOO9ruwssqY5utsqjRgyBmUxomnFimsEJaz\nhOXLkT4nNjdZi97UzEabA4A6WQhb9Rrs/dL1+Oo7N+DKNVX49O62vO1rxgzXaEopnjg6hKvWVGXM\nrm+rtWDIFUQwEkcsnpCam08OLfy5NOWLpIkDrdVGPPPpXfjRHdvw4heuxX98YDv8kTieTjbmXpxM\nt8Ic7HVAoyJ4+9pq6NSCpAiHIvGcKSyCQNBaNb2wcvojGHEXZwFv0WcexsSK93tuXS8V6krPxdZq\nE45+/Sa8cc8NsOrV2NORn6VlzB2CQMRdZE5x4IVwGbGqyoRBZzAtFodtGVaa8issTVoVonGqaJDE\n/p4p2E1arK01Z/XUZuKJo0Ootejwri0NuZ88zwgCwRduasea5AQ2qelB5oKWml2ZawhG6vNzNbRt\naa5AJJaQ/MCMF86MAQA+nOI335CiXi10IQyIucRyivBC+NC2NNmgFkhZNMyx3Ot8t1QFgeDzN7Vj\nY5FVyHIgX2sEpRRH+p1Swy1jY4MVPZN+HB2Y7iNgsIYmJQvRXAw6g9J5X0xqrdPnO7NGAOkNi4Vg\n0IiF8Exb1oQ3jL6pAHavr8vwncCaWhMoFYtKNm4XAE7IKMLnR73zGlU45QujLuV3VG3WwWbU4LZt\nTTBoVVhfb8WutmrUW/W4/bJmBCLxNMtBR68TW5ps0GtUqDbrpKbVYDQOvYJFTWrG8vlRL+IJWpTr\nllmnzngf3Nc1CbVACrZDmXRqNFUYcOOGOjx+ZDAvz/CoJ4Rqsw5qFS/figX/TZYRDRV6xBMU497p\nooxZI/JVhNmc80Akd/zL692TuGqNmIRgTSq5boVB4okExRsXJnFNe01Znpis6UEuNcITikldrXKB\n7jOZ9IVh1qlzNmFsTXpvj6fkRU76whj3hvGP79qQFq1j1WukY1jI1AHGpiYbxr1hjM/IPh6QUe+K\njV6jwrp6S5rXsVS4glEk6MINxFgMSNYIhYXwiDuEcW84LfMWAK5tF7e8v/GHMwDSdxlY8TPXsbOU\n0uR47OJP9qtLUYSZNaIY6LUqUDr798ssD9kWV6zgvzDhw2CyEbG9zoyTQ+60wvrlc2O4+Yd78WQB\nXlSlOPyRNB+vXMrDz++6HG/ccwOuTfq3R5KNyv+/vfOOjuws0/zzVbiVg1SSWqG71VLn4NDt1LYb\nZ8BkDzDgAWaGgSUsMLDAwjDjnRlmYA4zOyyYPfjAcoA95DCMCTOkBWOCwTbugN3u5FYHhVYolapK\nlfO3f9xQt6JulSqq3t85PpZK19K1dOu77/fe532eRDqLZ+aCuEHSV3vsgiKNSKRzmgbe3nnnDtx3\n7Sg8NgEXJWnh5gY8ybKbyzsvJTNZfPfEHJ6/b5Nyn62X10sa/we+96xmX+jFULKjZRHdSOdVLj1M\n3qg9X5TUK42wmSRf4jUG5s57I/CGk3jezgEAUCQNWgvh0wshBGNpHNkxUNP5tRK7qfzQw2o8jS19\nVgh6naZCeDmc1DRItbXfCrfViGdUCUKyPdC+MpG3D7/jFnzm9YeachNfCzmprrgrPOOPwWTQNf3x\n24DdhGCNwS/NQNYpt+Nv0KkoHWGNEit5Q1McP75/1IlRl7jJv+/a0ZKUzEGHSdP7rxrRVBapbK4p\nfz91R1iva9wtUw78KB5qPrMgPknaW2VjPDFgA2Pi8KE8IHfv/mEEY2mlMAagyBFqTUirBV8kVeD1\nW87316gXn8zJyZnyxufp2SDSWY4bxqVC2CYo0oh4OqtJbmQR9Hjw/oM4sjN/D2pECqwcrV3ML854\nEYil8dobtpT5r2rjuvE+fPp1B+GPpqrGkatZWk10RWxxN0GFcAchuwaojdLlUIzaXSOkjvAaEoff\nnBcjkY/sFHfqRr0OdpNB6USvhTykUc1SrN3IyVDFhOJpuCxGDDpMBV34SiyHk1WtfGQYY7hqzKV0\nhH90cgEf+9FZ6HWsbJdnyGFWbOtajZyWeK5IxnFhOYqJAVvThx3cViMCGq+1agRjKU1/w0rI5v3U\nEc5jNtYmjZA3e8X+xTodww/f/Tz8518ewSdec23JfzfkMGkaVq2GXyqemlEIi7Z04seN7AjL3c5i\nnfDZxRDG3JaqEdFmox7j/VacWwzjSjAOo57hrr2iROBjPz6Dbz01g4cencLDx8VOcPHmo1FwzrES\nTRa8b6olwQ1L9zhZiiYnW8rzAh67SdmUJtJZ5RrUgrpL2ohC0Wk2lPUR/v4f5jFgNzWs+XPH7iEw\nBvzugk/T8d5wYs05FaI2qBDuIEaKdssAEIilYRX0NQ/iyB3htSzUfjvlw8SArWAH7bIYEYxr69Kd\nXQzDKug72jjbYS6v9QolxEJ4QGNHKhhLa+7MH5704OxiGA/+/Dm842vHcWYxhH98xf6a3T+ajdNs\nxLDTjKmlQkuj896w4nXcTPqsQkM6wn/98Em87SvH6v7vZS0+dYTz1CqNOLsYxrjHCluZobE+m4AD\nY66yG6tBhwneMl7WnHO85rOPa/LHlR+nN+vvJxd6hgZuDC1SsyJeJF+7sBzBdg3vvf2j4lDufDCO\nYZcZ+0bEzvuPTi7ir/79JP71p+eUY2tNCtVKLJVFIl3Yia+WBDfkMIGxfCH8+8sB7N7kUNZFj12A\nL5oC5xzxVBaWGu57avvJRgyuOswGJNK5gmHR1XgavzjnxcuuGWmYFNBuMojyIA2+9ulsDoFYmjbs\nDYYK4Q7CaTbCYTKUSCNqlUUA+Y5wtIpGOJXJ4YmLKyU7W7fViFWNXbpzi+GOt0mpNPSwGk/DaTFg\n0K6tEF6NpzV35l8gDXA8+PPzuHGiH+c/+iK8/qZSz9dOYOcme0EyYDyVxVwg3hIzdJfFiFAig8w6\nb9QnZoKKrrkeVjTGK/cStQZqnFkIVX2cX4khhwm+SLJkoMsXSeH3l/1477eeXvN7yBKyZhXCcshK\nI+cg5CIvnspf+5xzXPbFqkY1y+wbdWLGH8O5xbBiI/b1txwucKX5/QN3A2heISzLGNTvm2pOD0a9\nDv1WAb5IEtkcx/HpgNINBsRuciqTQySZQSJTWyHcaF9dWeus9kn+6alFpDK5mq3y1mLEZVZs0aoh\nPyEeoI5wQ6FCuMMY67NgLpC/oZ+cWy0xDdeCTZFGVL6JnZgJIJbKFmirALEQDmrQlHHOcW4pjD2b\nOjs9xm42lkgjkhmxk+GyGDHkNGnKfg/GU5pt4XYM2XHXniG4rUb8zYv3duQgocyOITumvBGlELmw\nHAHnaFFHWPx9hmpMMlTjj6awGErAH01pHjgpZkVxZ6FCWKYWH+F4KotLK1FFalMLg5JPb/GaU+yp\nXo18QdacAmFcsuhqpPeCXDCqmxXLkSQiyQy2aYjPlf2Szy6GMSkNz20bsOGbbz2MHUN2/I+X7K25\nq1/MaiyNB757suIwo9yJV3co1/Lh7rcJ8EdSODW/ikgyUxBEIneTVyIpxFPaNMIylazm6kWej1A3\nSR45s4Qxt0UZiG4Um5xmLGpxLpK97DVI9AjtrG/kkWg42zw2nPeKes1ZfwznvZG6RPlWU+kiW8xj\nUz7oGHDzdk/B626LgLOra0/yL4eT8EdTdd38WondZCgptOQhCKfFiGxO7D4lqgxnJNJi4axV2sAY\nwxffeMP6TrxF7BxyIJ7O4kowji39VlyQkp/kmMxmIv8+A7H6J/5lbWqOi9+nnseG/qi4yTF28Ial\n1Zhq0Ag/txQG5/U5n8gDqN5wouAaUCeQpTK5qnZlirSlSQWCXJjONSD4Q0b2bFdv0i/7xO+/TUPz\n4/Bkft1+8VXDyscGvQ4/f9/tAKAEdqSz9ZXwb//qMTx+cQV7R5x4Q5kUQ2UDUsPvvd8mwB9N4Rdn\nvWAMBU8klS5sNIlEOldTIdzojrB8XcqFMOccx6YDuG3X4Lrjy4sZcZk1BWv4IjTL0Axo1e8wtg3Y\nMOOPIZ3N4YHvPQvGgLv3VvaTrITcbaikET4+E8AXH7uEW3cMKHGtMi6rUZNrhGzzs7eME0In4Sgz\n9CD//7ksRmwbkEz9q9zk5KlrZ5uCQprJLqngnZLkEeeXItDrGLZ5mp90J0tNtA5nlkNtv6als18O\nXyRZ0828FxCkTYGWYJ5qrihrIQdWFMuT1B3htbrD/lgKgl4Hmwa7rXo4JMkNGvn+l9dddZy9HKik\n5Smg2ajHB+/djV2b7Lh50lP2GHnzUK804g+z4sBvpQQ8tTb7tx+6C7/+wJ1rfk/ZIu3Rs14c3OIu\nsFuTJRZyY8IiaC9R5E3UB164e40jtSEXwvKaMr0Sgy+SwvXjtUVpa2HYZUYokVkzDdYnvUfKWdQR\n9UMd4Q5jcsCGdJbjP56ex6+fW8YDL95blzRC0QhXGBJ7w+efxIDdhI9LCWxq3BYjgrE0OOdVd75a\nbH46AbtJHHpIZ3NKx08pbM1GZQG95ItiVwWZh1w4uzdgISxLIM57w7hzzxCmvBGMe6zrDgzQgtwR\nXs/A3BlV1KwvnAKGqxxcgblAvCGWSxsJnY7BbNQhoaEQPrdU/9BscedNRp2yKRZclZ88+SPiE4VG\nd+pkbt0xgG+85XCBnnW9yB1htbXZrD8GvY5pvhbfcccOvOOOHRW/rtcx6Bg0BSuVQ5Ya+Su8P30q\nSYoWz18g3xGeDybwupu2FnxtQKXLjadr0wgzxnD5n1+i+fi1kDfG8nX5jOSQdHBrfSEa1ZC72Qur\nceyoMpuRl6LQpr2RUEe4w5gYFIveTz86BUGvw/031udVWC0h7pnZVcRSWfzTHx0oazPjthqRyfGy\n3rtqzi6GMOoyV7X56QTkG456U7CqdHgNymPIt33lGKa84dJvACj6xXZFRzcTt1XAoMOE85JzxHlv\nGDuakNBVjr5GdIQXQkqSVL0d4Vl/rKnhId2KVTCsGcoDiL+/rf3WuoZm89KIwr/dcjgJp/LerV6M\nNytMQ83N2z0Nlc44zKX6+Bl/DKNuc0NnCox6XV0d4URa9GYG8kNaxaxEUrAJes1FMAD020wIxNKI\np7MlBX+/0hFOavYRbhYmgx5uq1HR5V7wRsCYtm59rciSonLJgGp8kRRMBl3Ncd5EdagQ7jBkD86L\ny1HcuWewbv9HvU5MVAvFyxTCUh791WPld7b90sBJpcVP5sxCqONlEUB+U6A2R5edOYZdloLi9nsn\n5st+D7lQq9XPuVvYOSQ6R6QyOVxeibVEHwyIenQgP/VfK8lMFlPeiBIIU08hHElmEIiJ4SpEIRaj\nvsDVoBKz/njdGwm7yQCroC/pCPsiKWWTulYx7o+luk7aIhh0sBj1BamXM9KGotE/J1VHIazenPor\n3Av80WTNumy1w0TxEwTBoIPTbMDCagKcN8YGbT0M2PPWfhd9UWzuszTlnHZtcsBhNuCpy9VDNXxh\n0bO5WU8+ehUqhDsMh9mI26QYyrfeNrmu7+U0Gwr0ZzIn51Yx7rFW7ORW6tCoSaSzuLAc7YpCWBlK\nUXWEL69EIRh0GJE64m8+MlFyjJq8NKK7brZa2Sk5R1xeiSKb4y1xjADEv42OaU8yLObp2VVkchy3\n7RqEVdBX1XlXIh8nTdKIYiyCHvH02jHtc4HYurzEy6XL+SJJpSis9L6U8Ufrs5lsN05LYbNi1h9v\n+IZM0Ovqkkao35OVNqorRfHKWlB37sfKXDMDdpPinFSLNKIZ7B524NhMALkcx8XlCCYGmrMu6nUM\n14/3rTkwtxxJknVaE6BCuAN58LXX4rNvOITr1inKd1qMZaM1L/miVT1ihypo9gBRM/avPz2LD37n\nGWRzvOMdIwDAbhILfnVH+JIvinHVo9y/fek+7NpkV+JKi5E1rBtRGgEAOzY5EElmlKTBVngIA6IO\n1WUx1t0R/t0F0fnk8KQHV2924cRMsObvoRTC1BEuwSroKw5KyQRiaURT2XX9/gbthemOsVQGsVQW\n45JbQzUbSCCvEe42nGaj0qyIpTLwRZINl+jUK41Qr3mVOsK+SKpmvapaWrDZXfr/6rELuCLFRLe7\nI3z3niEsh5N41zeO49R8SJO/c73cuWcIF31RPLdUXp4HSL/vLrzOOx0qhDuQfpuAew+sP3JXvciq\n8UWSGHJW3lUqHeEyBt/femoWDz16AT94WpQQVJJXdBJ2pSOc/11Mr0RLLIrG3BZlAS4mFE+DsXx3\neaOxU+oA/+TZBQDA5GDzHSNkxHS5+jrCv7uwggNjLrgsRlw33oczC6E1C7diLkqOBK1wyeg2zEb9\nmumUcvduPR3hIWdhR9gXFgsvLR3hVCaHcDLTlWEoTkt+jZ71i2tPowthwaCryz5NnouYGLBVjEFf\niSRr7ggfGHMpkdVOS+l66rGZMCetw7W4RjQD2Qv+RycXYTbq8KpDm5v2s+49MAwdA358crHiMSuR\nJFmnNYGNeVcnAIiLzHxRbGMmm8NKNKWYhZej3ypAr2PKkICaY9MBCAYd9g478PJrx7BVg/F7u8lP\nZ4s302yOY3olhjt2DxUcN9ZnwYnZ8h3FYDwNp9nY0Ql660EuhJ+6HMC4x6q4jrQCl9VYVyEcS2Vw\nYiaAN0myluvH+/FQ7gKOTQdKQmKqMeWNYMhh6vihz3ZgFfQVu4EysrXZ+Do2EoN2Ex4L+5TP5bVn\nyGGGVdBXtZWSnyZ0YxiKw2xQvHhlWU+jNcJGPVuXNGJiwIan54LI5jj0qvWPcy4OKdahzT76wD1Y\nWE2U1boOu8yKprnd0gi3VcDRB+7BuaUw9DpWl0+2VoYcZmzz2Cp2hHM5jpVoCgOO7rvOOx3qCG9g\nynWEV6IpcJ7v+pZDp2MYsAvKkICaMwshHJ704PvvOqLoajsdWc4g/y4u+SJIZnLYXWSVNuq2IBhL\nl73p1hKv3I147Ca8955dsBj1+PDL9rf0Z/dZBQTjtUsjjl4OIJ3luGW7WPTeNNkPwaDDo+e8NX2f\n895Iy4YDuw1xWK56R/jichSMQZEx1MOQU/RRla3a5KHHAbsJVsGAaJVzKBfz2y2o1+jZphXC9Q3L\nrUqb093DDnBeKpULxTPI5Hhdv3eP3YQDY+XT2XYP59flVm7IK2HQ67B/1NXUIlhmc7+14pxDMJ5G\nNsepI9wEqBDAr+DoAAAZlUlEQVTewJTTCMuLWbVCWP56cUc4nc1hyhvB3i7QBatRjOul38UpKYBh\n/1jhwiYb+5dzHgjG0htWHyzznnt24uSHX4A79wytfXADcVuMCERr7wg/NuWDUc9wg+TtahUMODzp\nwaNntRfCnHNc8EZaZhfXbViEtaURjZimL46zlWVZQ04T7KbqHWHZW7UbQwacFoPSeZ3xx2AT9Iql\nYKMwGerUCMdT0OuYMhBdXKD5ysQrN4I9qkL46gZHGXc6W/osmA2UL4TVm0OisVAhvIFxmg0IJzPI\n5fL6MK2F8LDTjPmiwbHplShS2VzBQtUNyDZFq6pCWDDosL2o+JE7GytlHgWvxjd+IQygof6lWnFb\nhbpcI355zosbJ/oLukZ37h7ERV8Ul1VJZMlMFtd95Gf42pPTJd/j8koMkWQGuzs8FKZdWAX9moEa\nF7wRTK5zml4J1ZBu9jP+GEwGHQbtJthM1b2Ml0KyjKL7CoTxfhuCsTT80ZTiZd1oayxjna4RgVga\nbosR4/3lkzcvLYvvsXLOD+tBHWqkNdJ+o7Cl34pgLF1gqSezuCpuDqkQbjxUCG9gnBYjOEdBMIZS\nCK/xZto+ZMclXxQZVSfhsk9cCJtlIdNM1DZFp+ZXsWfYUWKOL0+d+yO9Wwi3A7fViEgyU9PNenol\niueWIrhjV2H3+i6pm/0LqSucyuTw7JUQVqIpPPDdZ0u+z1OX/ACAGycalxi2kbCsMSyXyeZw0Rcp\n2VTWSn5AN18IywEdNsFQdVhOdpuoNgDcqciuO2cXQjh5ZRU7KyRbrod6XSNkJ45RtwU6VloIH58J\nwKBjODDa2K6tzWTAa67fjE+8pjT1dKMjO6/Ig5Nqjk0HoGPAvlHatDcaKoQ3MMWSACDfcVmrI7xz\nyIF0lhcsfnLk6XgXJnA5zUasxsXY6FPzIewvs5gohXCFjvBG1gi3E/lRcC1d4f/z64sQ9Dq87JrR\ngtfHPTaMucWhxy8/fhn7//4neNtXjipfL45yfvKSH/02Yd2F3EbFIhgQT2cLniqpObsYRiKdwzVb\n1lcMDZV0hOOKVtZm0ldNlvOGklIoR/v1pLUi62F/8PQ8vOEkjuzwNPxniIEapX+/Mwsh/Pq55Yp/\nWzmtTzDoMOKyKBpmmeMzAewdcdaUKqeV//nqa/DKJjo0dCpyd72cjefjKoccorFQIbyBUcdVysix\npWvp+WQXgeeWInj4+BymvBHM+GNwmg1dWRC6JJui+dUEgrE09pXpYvRXkEbkchzBWGrDhmm0G5f0\n+LO4SK1ENJnBw8fn8EcHxzDsKo0Inxy04ZIvgk/+7Dmksxw+qcOvY8C//ORswbGn5ldx7RY3JTVV\nwCoVOckK3foTM2IS1qGt6+uo99sEMCauT5zzgshrq8mAaBVpxHI42ZWyCEB8MjdgF/DNp2YBAEd2\nDjb8Z5STRmRzHK/6zO/wZ1/8vWKFWcxKNKmk9e0eduDYdACci0Xzo2e9eOKiX0l0JBqDfB0Xz6lw\nzvGHuSBu2La+bAGiPFQIb2BG3GKRsLCat1DzhhNrdoMBURqh1zG8/avH8L5vP413ff04Lq/EMO6x\ndWXR4LSIHeFTV8Qs93IdYaugh8mggz9auAhFUhnk+MYN02g3bun3GtTQEY6lMnjDF55EIp3Dq68v\n3zGaGLDh2SshBGJp/P3L9uEj9x3AN95yGG+6dQLffGoWZxfFYclsjuOiL9qyFL1uRLavqqTRPTYd\nwJDDtC4PYUDUpntsJiyHE1iJphBJZpSOsF0wVB2W07qmdSKMMbzv+bsBAH96eBxj7sanGwoGViKN\nmPJGFMnLV58o1c4D+Y4wADx/3ybM+GP4488+jkQ6i089ch6TAza8++6dDT/fXkbeeBQ7dARiaaQy\nuXW/z4jyUCG8gZEXVfXQ23I4qemmYTcZ8MEX7laMz88uhvHr55ZbGrTQSOSO8Kn5EHQM2FtmOIox\nBo9NKOkIyzZC5DPbHORo3MAafrUA8ORFP07MBDFgN+G6Cl1IdTDG83YO4E8Pj+Pm7R68664dsAsG\nPPToBQDi+yKVyWF7l17TrUB+7B2vMDB3bCaA68b7GrI53uQ0YSmUxJQ3AkDcjAOi1646FbIYbziJ\nIWfpk4Fu4XU3bcWvP3An/uHlzbEtFMpohOVO/n3XjuLodKBkOCub4wjG0+iXwjJesG8TAODodAAP\n/vw8/jAbxOtu2tr25LeNhsmgh9tqLCmEFR28o3uv805GUyHMGLuXMXaOMTbFGPtQleNexRjjjLHr\nG3eKRL24LEZYjPqCjrBYCGt7M73t9u149sMvxCPvv1157fnSgthtOM0GrMbSODW/islBe0VdW79d\nKNEIy9pV6gg3B1lqo6UjLN8QvvfOWyqGm6j9bNVuBm6rgNfcsAU/PrkAbyiBqWWx4JokfXBFZGlE\nOS9hbziBWX983bIImRGX6FQjF8Jyp95lMSKWypYd+Aol0rgSiHfl3IKarR5r08J6ykkjnrmyCpfF\niJdcLWrsi0McAjHRb1520vHYTTj30XuxY8iOz/5K3Ejed3CsKefb6wzYTSWFsOyMsqkLB0K7gTUL\nYcaYHsBDAF4EYB+AP2GM7StznAPAewA82eiTJOqDMYYRt7m0I1yD/YrNZMD2QTvu2SsWwHfv6c5C\n2GUxIpzM4Om51bKyCJkRl6XAegvIF8JuKoSbglwIr2pIl5NvENUshK4b78Ptuwbxw3cfKSku7rt2\nDJkcx9HpgGL/NDlAHeFK2EziAFq4jDThxIyYwnhovDEx68MuMxZDCUx5I7AKeoxK+m9XlWHK3573\nIZPjuG1X47W1GwVjGR/hhWAcW/otigPB6YXCQlhuBvSrwjJMBj0+9sqr4DAZ8O67d5KNV5MYtJd6\n+Mu+2pu6+MlHJ6NlzPZGAFOc84sAwBj7JoBXADhddNxHAPwLgA809AyJdTHqsmBe6ghHkxlEU9m6\nbIY+84ZDWI2nmzIh3Ap2DzuVdKRqdj+HJz342eklPHx8TplaDpI0oqnYTQYYdEyJyq2GN5yEy2Ks\n+kjWbRXwpTfdWPZr2wbynqj+aAomg67gZk8U4pAK4UgZacKpK6vQMWB/g+yzRlxisuPJK6vYPmhX\n5Bbyk5jVeLqk+PrluWU4zAYc2tqYYnwjIpTpCHvDSWxymjHqMsNhNuDMQqjg6/KwVnFq3A3b+nH0\nb++B0Aa/8V5h0GHCH2aDBa95Nfr/E/Wh5WoeAzCr+nxOek2BMXYIwBbO+Q8beG5EA9g+aMP5pTBS\nmZymbloljHpdV3cAbtuVn25+8dUjFY87skM87n3ffhrHpkUdXb4jTAVTM2CMwW01apJGaNW4V8Jh\nNqLfJmB6JYalUAJDTlNXDn+2CodkwVhOo3t6IYTtg/aG6URHpA7wsekArlIlijkt5TvCnHP86rll\nPG/nQFuCYLoF0T6tsBBeColOG4wxHNrah99O+RRHCACYC4hPEcuFZZgMenrPNJEhhwlLoUSBrZ03\nlFizAUDUz7pXD8aYDsAnALxfw7FvZYwdZYwdXV5eXu+PJjRwy44BxFJZnJgJKD7Ajc6y7wYcZiPu\nv2EL3njLtqqT2bs22fGW500AAH51TgxlCMbFTiVphJuHy2LUZJ/mrVHaU44t/VbM+mPwhpLYRMMn\nVXGYJWlEmaSr0/Ohhpr7q63wblTZRCkd4SLpzJmFMBZDiZJQFaIQo54hrfIRzmRzWInmLedesH8T\npldi+MJjl3B6PoRsTrSv0zFgtAkuFkR1dg87kMyIQTUy8saFaA5apBFXAGxRfb5Zek3GAeAAgF9K\nu8RhAD9gjL2cc35UdRw4558D8DkAuP7668u7eBMN5ebtHuh1DJ965Dxu2S6atffqlPw/v+rqNY9h\njOGBl+zD8ZkgfnXeh/e9YDdW42kIBh3MRuo6NYs+q6BIUKqxHE7i4Dofg4/3W3FiNgCjXtd1ceGt\nJl8IF3aEA9EU5lcT2DfSuEJYHa17w0SZQrioI/z1309D0Otw5x4qhKsh6PXI5jiyOQ69jmElKg7C\nDUp60xfuH8anfn4eH/3hGQDA3hEnBuwCRlyWkvRNovlcs0Vc3/4wu4odQ+J7YimcIH1wE9FylT8F\nYCdjbIIxJgC4H8AP5C9yzlc55wOc822c820AngBQUgQT7cFpNuIjrziA311Ywcf/33NwW42kidTA\nwS1unF0QuyOrsTTcFiM9DmwiHruApVDe3eSrT0zj7v/1y5LjlsPJdUt0tnmsuBKIYy4QJzuiNbAJ\nBjBW2hGWNaWN7AgP2E145P2343N/el3BU5tyhfBKJIl/OyqGqpBusjomaQOfkCzw5BhrucM4YDfh\nN391J77/zlvxz6+8CheWI/jNeV9PPjnsBLYP2mEV9HhmLq8T9lJHuKmsWQhzzjMA3gXgpwDOAPg2\n5/wUY+wfGWMvb/YJEuvndTdtxT17xa6J1Uj6Li3sGLIjmcnhSiCO1XiaZBFNZmLAjhl/DBlJy/jE\nxRVcWI4WDPnEU1nE09l1b+R2bHIgx4FUJlfX4GgvodMx2AVDiWvEaakQ3tvAjjAgFgEv2D9c8Fq5\nQvhLj08jmcnhLbdNNvTnb0TkUBSlEFY8afPXvsmgxzVb3Lj/xq346xftAdCbErpOQK9jmBy0KZHW\nnHMxPZE6wk1DUzg75/xHAH5U9NrfVTj2jvWfFtFoPnrfVbiw/AReWmVQjMgje5hOLYcRjKW7Mla6\nm5gctCGd5ZgNxDExYMMlycIumsxAMEiBG7FSS6d62KlKkhumm8ualAu0OD0fwianqSUDtEa9DlZB\nrxTCsVQGX378Mu7Zu4lSATUgS7oS0qZStkbz2Mr/7d54yzaE4pmCAWOitXhsJiXYKRhLI5XNUUe4\niWgqhInuZ9hlxi/efzt1gzWiFMLeCILxNMbcVDA1k+1SqMXF5Qi2eaxKIRxJZtBnKyyE+9a5KZlQ\n+QYf2Uk3+7Wwmw0l0ojTC6GG6oPXwm0xKsmD335qFsFYGm+/nbrBWjAXdYTl95HbVv59xBjDe+6h\n6OR24rELSrDMUpg8hJsNKeF7CCqCteO2Chh0mHB2MQxvKNHV1nHdgDzAeWE5gqVQEjEpySyieiQf\niIrFmBzJXC9yYTDmtpBGWAMOs7GgI5xIZzHljTRUH7wWI24LFlYTyOY4Pv/YJRza6sb1KmcJojIm\nQ3EhnIZBxxSPaKLz8NgErEST4JxTqlwLoHcCQVTgwKgTj19YwUo0VdBFJBqP2yrAYxNwcTlaYBuk\nLoT9DZJGAMCJv30+BAP1AbTgMBuwEslb2015I8jkOPaNNCZIQwsjLjNOXlnFmYUQ5gJxvO/5u1r2\ns7sdOQRJLoSDsRTcVoEaIx2Mx25CIp1DLJXFgpQMSx3h5kF3AoKowIExFxakVL7JQdIiNpvJQRsu\nLEcUWQRQmGgm+wz3NaAQ7rMJSnwwUR2xI5yXRpyeb7xjxFqMSR3hp6VJ+uvG+1r2s7sds0F2jRA1\nwoFoet3yIqK5yIl+/mgKl1aiEPQ68nRuIlQIE0QF1NGx1BFuPpMDdrEjvJwvhNVuBfKQj5scPFrK\nqMuM+WACacnR4/RCCFZBj/EWugqMui1IZXJ49KwXLouRHA1qoFgj7I+l1i0vIpqLLMXzRZK47Iti\nS78Feh118JsFFcIEUYHnqQap6MbbfLYP2bASTeHETEDpWEULNMIpOM0GitNtMftGnUhlc7iwLEpW\nTs+HsHfECV0Lb8xy/PLPz3hx1ZiLHuvXQL4QFjcyojSCNpOdTL+6I+yLYmKAnkg2E7qjEEQFbCYD\n/vMvj+Bjr7yK9KQtQE4WOz4TxFWbxXQltTTCH0tTGEwbkN0hTs+HkMvxljtGAMDmvvxGVJ1AR6yN\n7CMcVw3L0fuos5E3ftMrMUyvxDAxQI2YZkJ3d4KowoExF/7kxq3tPo2e4KYJj/Lx7bsGARRKI4Kx\nVEP0wURtTAzYIBh0yqBaJJlpqT4YQIFf8PYhkinVglmVLMc5V4bliM5l0GGCxybgP56ZRzKTw07a\n/DUVKoQJgugILIJe6YS8+rrNsJsMBdIIfzSFfrqBtxyDXoc9ww6cXgjh9MIqALS8I6x+IrODBldr\nwqTSCPujKaSznMIZOhzGGPaNOnFiRhwOvZGsApsKFcIEQXQM//b2m/HwO26By2KEzaQvkEYEotTJ\nahf7Rpw4PR/CqfkQdAzYPdz6DpVVsgHbTmlyNSF3hJOZHOYCohXX5j5yIOh05KcuHpuAcQ9JI5oJ\n+QcRBNExbO6zKnpQu8mAcDJv2+WPpdBfIQ2LaC57R5z45lOzePScF9sH7coAViv51ltvxk9PLSrW\nUoQ2BL0OOgbEU1lVIUyFVafz6kObMbUUwc3bPTQc2mSoECYIoiPx2E3wSUEO8VQWiXSONMJt4sCY\n2J169koI91072pZzuGqzC1dtbl2Ix0aBMQazUY9EOosrwRgAYIw6wh3Pzk0OfOGNN7T7NHoCkkYQ\nBNGRDDpMWA6L8aIBOVWOpBFt4WrJxQMAbtkxUOVIohMxG/VIZMSOsNNsgIu8uAlCgQphgiA6kiGH\nCd6QmOynhGlQIdwWjNLjdaDQX5voDswGHRLpHGb8MYyRLIIgCiBpBEEQHcmgw4RoKotoMpPvCJM0\nom38+3+9BY+d92HERY/Vuw2zIEojzi9FKJ6aIIqgQpggiI5kyCFaqS2Hk1iJUCHcbg5u7cPBrVRE\ndSNmgx7eUBJXgnG87ibyRScINSSNIAiiI5G9TpcjSVxeiYIxsn0iiHqYGLDh95f9AIA9bbC+I4hO\nhgphgiA6kkGpEF4KJXDZF8Woy9IW2y6C6HYObs0PO+5pcRgKQXQ6VAgTBNGRbO23gjHg/FIEl3xR\nTA5StC5B1MMhSRfsMBsw5qanKgShhgphgiA6EpvJgB2Ddpy8soqLvii2eagQJoh6uHrMhTfdOoHv\nvuPWdp8KQXQcNCxHEETHctVmFx4+fkX5mCCI2jHodfi7l+1r92kQREdCHWGCIDqWw5MeAMBNE/14\n5cGxNp8NQRAEsdGgjjBBEB3LH1+3GXfsHoTHZoJeTnQgCIIgiAZBhTBBEB0LY0zxEyYIgiCIRkPS\nCIIgCIIgCKInoUKYIAiCIAiC6EmoECYIgiAIgiB6EiqECYIgCIIgiJ6ECmGCIAiCIAiiJ2Gc8/b8\nYMaWAUy35YcDAwB8bfrZRHdB1wqhFbpWCK3QtULUAl0vjWGccz5Y/GLbCuF2whg7yjm/vt3nQXQ+\ndK0QWqFrhdAKXStELdD10lxIGkEQBEEQBEH0JFQIEwRBEARBED1JrxbCn2v3CRBdA10rhFboWiG0\nQtcKUQt0vTSRntQIEwRBEARBEESvdoQJgiAIgiCIHqenCmHG2L2MsXOMsSnG2IfafT5Ee2GMbWGM\nPcoYO80YO8UYe4/0ej9j7GeMsfPSv/uk1xlj7H9L188zjLFD7f0/IFoNY0zPGDvBGPtP6fMJxtiT\n0jXxLcaYIL1ukj6fkr6+rZ3nTbQexpibMfYdxthZxtgZxtjNtLYQ5WCMvVe6Bz3LGPsGY8xMa0vr\n6JlCmDGmB/AQgBcB2AfgTxhj+9p7VkSbyQB4P+d8H4DDAN4pXRMfAvAI53wngEekzwHx2tkp/fNW\nAJ9p/SkTbeY9AM6oPv8XAJ/knO8AEADwZun1NwMISK9/UjqO6C0+BeAnnPM9AK6BeN3Q2kIUwBgb\nA/BuANdzzg8A0AO4H7S2tIyeKYQB3AhginN+kXOeAvBNAK9o8zkRbYRzvsA5Py59HIZ4oxqDeF18\nSTrsSwDukz5+BYAvc5EnALgZYyMtPm2iTTDGNgN4CYDPS58zAHcB+I50SPG1Il9D3wFwt3Q80QMw\nxlwAbgPwBQDgnKc450HQ2kKUxwDAwhgzALACWACtLS2jlwrhMQCzqs/npNcIAtLjpYMAngSwiXO+\nIH1pEcAm6WO6hnqbBwF8EEBO+twDIMg5z0ifq68H5VqRvr4qHU/0BhMAlgH8X0lK83nGmA20thBF\ncM6vAPg4gBmIBfAqgGOgtaVl9FIhTBBlYYzZAfw7gP/GOQ+pv8ZFWxWyVulxGGMvBeDlnB9r97kQ\nXYEBwCEAn+GcHwQQRV4GAYDWFkJE0om/AuLmaRSADcC9bT2pHqOXCuErALaoPt8svUb0MIwxI8Qi\n+Guc84ell5fkx5LSv73S63QN9S63Ang5Y+wyRFnVXRA1oG7pcSZQeD0o14r0dReAlVaeMNFW5gDM\ncc6flD7/DsTCmNYWoph7AFzinC9zztMAHoa43tDa0iJ6qRB+CsBOaRJTgChG/0Gbz4loI5Ku6gsA\nznDOP6H60g8A/Ln08Z8D+L7q9T+TJrwPA1hVPeYkNjCc87/mnG/mnG+DuHb8gnP+egCPAni1dFjx\ntSJfQ6+WjqfuX4/AOV8EMMsY2y29dDeA06C1hShlBsBhxphVuifJ1wqtLS2ipwI1GGMvhqjz0wP4\nIuf8n9p8SkQbYYwdAfAbACeR133+DUSd8LcBbAUwDeA1nHO/tEh9GuJjqxiAv+CcH235iRNthTF2\nB4D/zjl/KWNsEmKHuB/ACQBv4JwnGWNmAF+BqDv3A7ifc36xXedMtB7G2LUQBysFABcB/AXE5hOt\nLUQBjLF/APBaiE5GJwD8F4haYFpbWkBPFcIEQRAEQRAEIdNL0giCIAiCIAiCUKBCmCAIgiAIguhJ\nqBAmCIIgCIIgehIqhAmCIAiCIIiehAphgiAIgiAIoiehQpggCIIgCILoSagQJgiCIAiCIHoSKoQJ\ngiAIgiCInuT/A4JPPb12YMrHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPb1LDSi9krt",
        "colab_type": "text"
      },
      "source": [
        "## Elementary approch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGmrGoIOzgwP",
        "colab_type": "code",
        "outputId": "7ecda0ff-fec9-4d79-efe9-1fe15eb2b5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "print(y_train[:5])\n",
        "X_train.head()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3' '7' '6' '3' '4']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>835</th>\n",
              "      <th>836</th>\n",
              "      <th>837</th>\n",
              "      <th>838</th>\n",
              "      <th>839</th>\n",
              "      <th>840</th>\n",
              "      <th>841</th>\n",
              "      <th>842</th>\n",
              "      <th>843</th>\n",
              "      <th>844</th>\n",
              "      <th>845</th>\n",
              "      <th>846</th>\n",
              "      <th>847</th>\n",
              "      <th>848</th>\n",
              "      <th>849</th>\n",
              "      <th>850</th>\n",
              "      <th>851</th>\n",
              "      <th>852</th>\n",
              "      <th>853</th>\n",
              "      <th>854</th>\n",
              "      <th>855</th>\n",
              "      <th>856</th>\n",
              "      <th>857</th>\n",
              "      <th>858</th>\n",
              "      <th>859</th>\n",
              "      <th>860</th>\n",
              "      <th>861</th>\n",
              "      <th>862</th>\n",
              "      <th>863</th>\n",
              "      <th>864</th>\n",
              "      <th>865</th>\n",
              "      <th>866</th>\n",
              "      <th>867</th>\n",
              "      <th>868</th>\n",
              "      <th>869</th>\n",
              "      <th>870</th>\n",
              "      <th>871</th>\n",
              "      <th>872</th>\n",
              "      <th>873</th>\n",
              "      <th>874</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26398</th>\n",
              "      <td>8</td>\n",
              "      <td>-3</td>\n",
              "      <td>-7</td>\n",
              "      <td>-7</td>\n",
              "      <td>-7</td>\n",
              "      <td>-4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>34</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>-2</td>\n",
              "      <td>-8</td>\n",
              "      <td>-17</td>\n",
              "      <td>-25</td>\n",
              "      <td>-42</td>\n",
              "      <td>-56</td>\n",
              "      <td>-53</td>\n",
              "      <td>-43</td>\n",
              "      <td>-39</td>\n",
              "      <td>-30</td>\n",
              "      <td>-19</td>\n",
              "      <td>-6</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>50</td>\n",
              "      <td>59</td>\n",
              "      <td>58</td>\n",
              "      <td>53</td>\n",
              "      <td>43</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>56</td>\n",
              "      <td>67</td>\n",
              "      <td>54</td>\n",
              "      <td>39</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>51</td>\n",
              "      <td>48</td>\n",
              "      <td>42</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>26</td>\n",
              "      <td>37</td>\n",
              "      <td>44</td>\n",
              "      <td>41</td>\n",
              "      <td>49</td>\n",
              "      <td>54</td>\n",
              "      <td>48</td>\n",
              "      <td>36</td>\n",
              "      <td>34</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>35</td>\n",
              "      <td>39</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>35</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22004</th>\n",
              "      <td>27</td>\n",
              "      <td>53</td>\n",
              "      <td>56</td>\n",
              "      <td>34</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>26</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>42</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>32</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>28</td>\n",
              "      <td>48</td>\n",
              "      <td>56</td>\n",
              "      <td>51</td>\n",
              "      <td>53</td>\n",
              "      <td>67</td>\n",
              "      <td>75</td>\n",
              "      <td>77</td>\n",
              "      <td>74</td>\n",
              "      <td>65</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>80</td>\n",
              "      <td>107</td>\n",
              "      <td>109</td>\n",
              "      <td>90</td>\n",
              "      <td>65</td>\n",
              "      <td>43</td>\n",
              "      <td>35</td>\n",
              "      <td>42</td>\n",
              "      <td>45</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>34</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>-2</td>\n",
              "      <td>8</td>\n",
              "      <td>33</td>\n",
              "      <td>42</td>\n",
              "      <td>39</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>39</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18517</th>\n",
              "      <td>54</td>\n",
              "      <td>52</td>\n",
              "      <td>51</td>\n",
              "      <td>50</td>\n",
              "      <td>34</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>27</td>\n",
              "      <td>41</td>\n",
              "      <td>43</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>21</td>\n",
              "      <td>26</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>21</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "      <td>32</td>\n",
              "      <td>38</td>\n",
              "      <td>51</td>\n",
              "      <td>60</td>\n",
              "      <td>65</td>\n",
              "      <td>59</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>42</td>\n",
              "      <td>49</td>\n",
              "      <td>43</td>\n",
              "      <td>37</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>45</td>\n",
              "      <td>56</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>55</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>65</td>\n",
              "      <td>54</td>\n",
              "      <td>38</td>\n",
              "      <td>28</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>40</td>\n",
              "      <td>50</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31615</th>\n",
              "      <td>87</td>\n",
              "      <td>80</td>\n",
              "      <td>74</td>\n",
              "      <td>76</td>\n",
              "      <td>73</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>32</td>\n",
              "      <td>38</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>38</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>57</td>\n",
              "      <td>51</td>\n",
              "      <td>38</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>-8</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>-6</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>39</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>-3</td>\n",
              "      <td>-4</td>\n",
              "      <td>-6</td>\n",
              "      <td>-12</td>\n",
              "      <td>-11</td>\n",
              "      <td>-3</td>\n",
              "      <td>6</td>\n",
              "      <td>-4</td>\n",
              "      <td>-24</td>\n",
              "      <td>-30</td>\n",
              "      <td>-22</td>\n",
              "      <td>-10</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>-8</td>\n",
              "      <td>-14</td>\n",
              "      <td>-13</td>\n",
              "      <td>-9</td>\n",
              "      <td>-5</td>\n",
              "      <td>-2</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>-8</td>\n",
              "      <td>-10</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>33</td>\n",
              "      <td>57</td>\n",
              "      <td>71</td>\n",
              "      <td>55</td>\n",
              "      <td>41</td>\n",
              "      <td>50</td>\n",
              "      <td>68</td>\n",
              "      <td>74</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20444</th>\n",
              "      <td>43</td>\n",
              "      <td>53</td>\n",
              "      <td>51</td>\n",
              "      <td>36</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>28</td>\n",
              "      <td>35</td>\n",
              "      <td>33</td>\n",
              "      <td>26</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "      <td>41</td>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "      <td>38</td>\n",
              "      <td>51</td>\n",
              "      <td>65</td>\n",
              "      <td>64</td>\n",
              "      <td>54</td>\n",
              "      <td>51</td>\n",
              "      <td>54</td>\n",
              "      <td>56</td>\n",
              "      <td>...</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>-5</td>\n",
              "      <td>-3</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>32</td>\n",
              "      <td>36</td>\n",
              "      <td>39</td>\n",
              "      <td>28</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>42</td>\n",
              "      <td>27</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 875 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0   1   2   3   4   5   6   7  ...  867  868  869  870  871  872  873  874\n",
              "26398   8  -3  -7  -7  -7  -4   0   2  ...   24   35   39   33   20   19   35   43\n",
              "22004  27  53  56  34  10  13  26  23  ...   33   42   39   28   27   29   39   50\n",
              "18517  54  52  51  50  34  16  12  27  ...    9   20   24   24   19   16   25   39\n",
              "31615  87  80  74  76  73  60  40  21  ...   57   71   55   41   50   68   74   69\n",
              "20444  43  53  51  36  18  11  24  27  ...   27    9    2   -2    2    9   13   11\n",
              "\n",
              "[5 rows x 875 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkCfZtWbzgwW",
        "colab_type": "code",
        "outputId": "8fefd489-19c0-45d4-958d-dbbf73a18c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# clf = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(500,1000,500,100,10), alpha=1e-5, random_state=1,verbose =True)\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# pred = clf.predict(X_test)\n",
        "# score = clf.score(X_test,y_test)\n",
        "# print('\\n', score)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(500, 1000, 500, 100, 10),\n",
              "              learning_rate='constant', learning_rate_init=0.001, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0.10290421669924601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_ccwFUmzgwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(list(pred[:15]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrVmz1pbzgwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# metric = y_test==pred\n",
        "# metric = metric.to_list()\n",
        "\n",
        "# t = metric.count(True)\n",
        "# f = metric.count(False)\n",
        "\n",
        "# print( round(t / (t+f),3), \"% are correct\")\n",
        "\n",
        "\n",
        "def benchmark(pred, y_test = y_test):\n",
        "  print( \"hamming_loss: \\t\\t\"    ,round(hamming_loss(y_test,pred),3))\n",
        "  print( \"precision_score: \\t\"   ,round(precision_score(y_test,pred,average='micro'),3))\n",
        "  print( \"recall_score: \\t\\t\"    ,round(recall_score(y_test,pred ,average='micro'),3))\n",
        "  print(\"------------------------------\")\n",
        "  print( \"accuracy_score: \\t\"    ,round(accuracy_score(y_test,pred),3))\n",
        "\n",
        "# benchmark(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yTowez-zgwm",
        "colab_type": "code",
        "outputId": "584d2436-ba58-4842-e80f-eb44ee3c9a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "DTC = DecisionTreeClassifier() \n",
        "RFC = RandomForestClassifier(n_estimators=25, random_state=1)\n",
        "ETC = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', DTC), ('rf', RFC),('et',ETC)], voting='hard') \n",
        "# for clf, label in zip([DTC, RFC,ETC, eclf], ['DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'Ensemble']): \n",
        "#     _ = eclf.fit(X_train,y_train)\n",
        "#     pred = eclf.score(X_test,y_test)\n",
        "#     print(\"Acc: %0.10f [%s]\" % (pred,label))\n",
        "\n",
        "# _ = eclf.fit(X_train,y_train)\n",
        "# print(eclf.score(X_test,y_test))\n",
        "\n",
        "# pred = eclf.predict(X_test)\n",
        "# tmp = y_test[:15]\n",
        "\n",
        "# print(pred[:15])\n",
        "# print(tmp)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0967606813739179\n",
            "['0' '0' '1' '5' '2' '0' '4' '4' '0' '3' '1' '7' '0' '1' '1']\n",
            "['7' '6' '4' '5' '1' '8' '2' '9' '7' '9' '3' '0' '6' '2' '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doQLOoBaCCa8",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "* Acc: 0.1008280565 [DecisionTreeClassifier]\n",
        "* Acc: 0.1022893327 [RandomForestClassifier]\n",
        "* Acc: 0.1081344374 [ExtraTreesClassifier]\n",
        "* Acc: 0.1074037993 [Ensemble]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkI0iEj9G9me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.tree import ExtraTreeClassifier\n",
        "# '''\n",
        "# SGDClassifier# .10 doesnt work \n",
        "# ComplementNB # .10 doesnt work \n",
        "# GaussianNB   # .10 doesnt work \n",
        "# ExtraTreeClassifier # .10 doesnt work \n",
        "# '''\n",
        "\n",
        "# clf = ExtraTreeClassifier()\n",
        "# _ = clf.fit(X_train_trans,y_train)\n",
        "\n",
        "# print('\\n Acc: ',eclf.score(X_test_trans,y_test))\n",
        "\n",
        "# pred = eclf.predict(X_test_trans)\n",
        "# print(pred[:15])\n",
        "# print(y_test[:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFI4AxjcUYHE",
        "colab_type": "code",
        "outputId": "0f36b0c5-bebe-4664-bf0f-79c54f6f26df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(X_test_trans[0])\n",
        "# test = X_test_trans[0]\n",
        "# test=test.reshape(-1,1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f13a9ac16a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIljit4wDCNx/g9aIxM+eIqYjAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohkUNdHAIXRs",
        "colab_type": "text"
      },
      "source": [
        "### Basic ANN  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft3yQ2g2zgwq",
        "colab_type": "code",
        "outputId": "fe646f3a-efb6-4cf8-8735-3808c81ea3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "tf.config.experimental.list_physical_devices()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
              " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0GKrkAozgwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dim = X_train.shape[1]\n",
        "\n",
        "# classifier = Sequential()\n",
        "# #First Hidden Layer\n",
        "# classifier.add(Dense(50, activation='relu', input_dim=dim))\n",
        "# # classifier.add(Dense(100, activation='relu'))\n",
        "# # classifier.add(Dropout(0.07))\n",
        "# # classifier.add(Dense(50, activation='relu' ))\n",
        "# # classifier.add(Dropout(0.07))\n",
        "# # classifier.add(Dense(20, activation='relu'))\n",
        "# classifier.add(Dense(1, activation='softmax'))\n",
        "\n",
        "# classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta-wW2Sxzgw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard = TensorBoard(histogram_freq=0,\n",
        "#                           write_graph=True,\n",
        "#                           write_images=True)\n",
        "\n",
        "# history = classifier.fit(X_train_trans,y_train, batch_size=8, epochs=1, validation_data=(X_test_trans,y_test) , callbacks=[tensorboard]).history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGYmOtB_zgw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_model=classifier.evaluate(X_train_trans, y_train,verbose=0)\n",
        "# print(eval_model)\n",
        "\n",
        "# eval_model=classifier.evaluate(X_test_trans, y_test,verbose=0)\n",
        "# print(eval_model)\n",
        "\n",
        "# predictions=classifier.predict(X_test_trans)\n",
        "# print(predictions)\n",
        "# # predictions =(predictions>0.80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPQbUDGkzgxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(history['loss'])\n",
        "# plt.plot(history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper right');\n",
        "\n",
        "\n",
        "# fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error,pos_label=1)\n",
        "# roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# plt.title('Receiver Operating Characteristic')\n",
        "# plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.plot([0,1],[0,1],'r--')\n",
        "# plt.xlim([-0.001, 1])\n",
        "# plt.ylim([0, 1.001])\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHYdaAlczgxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X[10000:], y[10000:], test_size=0.2, random_state=42)\n",
        "# mms = MinMaxScaler()\n",
        "# X_train_trans = mms.fit_transform(X_train)\n",
        "# X_test_trans = mms.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7yb2HQHzgxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# maxlen = 952\n",
        "# max_features = 200\n",
        "# X.shape\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "# model.add(Bidirectional(GRU(64))) # LSTM\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "# # categorical reference https://elitedatascience.com/keras-tutorial-deep-learning-in-python\n",
        "\n",
        "# model.compile('adam', 'categorical_crossentropy', metrics=['accuracy']) # was using binary_crossentropy\n",
        "\n",
        "\n",
        "\n",
        "# print('Train...')\n",
        "\n",
        "# yyy = enc.transform(y_train.reshape(-1, 1))\n",
        "# yy = enc.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# model.fit(X_train_trans, yyy,\n",
        "#           batch_size=32,\n",
        "#           epochs=4,\n",
        "#           validation_data=[X_test_trans, yy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOKsH6DKTVJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred = model.predict(X_test_trans)\n",
        "\n",
        "# eval_model=model.evaluate(X_train_trans, y_train,verbose=0)\n",
        "# print(eval_model)\n",
        "\n",
        "# eval_model=model.evaluate(X_test_trans, y_test,verbose=0)\n",
        "# print(eval_model)\n",
        "\n",
        "# predictions=model.predict(X_test_trans)\n",
        "# # predictions =(predictions>0.80)\n",
        "\n",
        "# benchmark(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHCG13WezgxI",
        "colab_type": "text"
      },
      "source": [
        "## Try EEGModels package - fancy 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b10YMKClzgxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://raw.githubusercontent.com/vlawhern/arl-eegmodels/master/EEGModels.py\n",
        "# import EEGModels as EM\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maQ9puBMzgxN",
        "colab_type": "code",
        "outputId": "c2b5aad0-15d5-4805-cea9-47adcfcee5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# idea from https://github.com/Cerebrock/BCI/blob/9e670f2b30cbe1e74579637bfeff1b232aa8642a/mnist.ipynb\n",
        "\n",
        "\n",
        "\"\"\" Keras Implementation of EEGNet\n",
        "http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n",
        "\n",
        "Inputs:\n",
        "    \n",
        "  nb_classes      : int, number of classes to classify\n",
        "  Chans, Samples  : number of channels and time points in the EEG data\n",
        "  dropoutRate     : dropout fraction\n",
        "  kernLength      : length of temporal convolution in first layer. We found\n",
        "                    that setting this to be half the sampling rate worked\n",
        "                    well in practice. For the SMR dataset in particular\n",
        "                    since the data was high-passed at 4Hz we used a kernel\n",
        "                    length of 32.     \n",
        "  F1, F2          : number of temporal filters (F1) and number of pointwise\n",
        "                    filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n",
        "  D               : number of spatial filters to learn within each temporal\n",
        "                    convolution. Default: D = 2\n",
        "  dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
        "\"\"\"\n",
        "\n",
        "nb_classes =10\n",
        "Chans = 1 #64\n",
        "Samples = maxlen # was 128\n",
        "dropoutRate = 0.5\n",
        "kernLength = 100\n",
        "F1 = 8\n",
        "D = 2\n",
        "F2 = 16\n",
        "norm_rate = 0.25\n",
        "dropoutType = 'Dropout'\n",
        "\n",
        "if dropoutType == 'SpatialDropout2D':\n",
        "    dropoutType = SpatialDropout2D\n",
        "elif dropoutType == 'Dropout':\n",
        "    dropoutType = Dropout\n",
        "else:\n",
        "    raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
        "                      'or Dropout, passed as a string.')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(F1, (1,kernLength) , padding = 'same', input_shape =  (1,Samples,1), use_bias= False)) # (1,Chans,Samples), use_bias= False))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "model.add(DepthwiseConv2D((Chans, 1), use_bias = False, \n",
        "                                depth_multiplier = D,\n",
        "                                depthwise_constraint = max_norm(norm_rate))) # was chans = 64\n",
        "\n",
        "model.add(Conv2D(F1, (1,kernLength) , padding = 'same', use_bias= False)) # (1,Chans,Samples), use_bias= False))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "model.add(DepthwiseConv2D((Chans, 1), use_bias = False, \n",
        "                                depth_multiplier = D,\n",
        "                                depthwise_constraint = max_norm(norm_rate))) # was chans = 64\n",
        "\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "model.add(Activation('elu'))\n",
        "model.add(AveragePooling2D((1, 2))) # 1,4 \n",
        "model.add(dropoutType(dropoutRate))\n",
        "\n",
        "model.add(SeparableConv2D(F2, (1, 16), use_bias = False, padding = 'same'))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "model.add(Activation('elu'))\n",
        "model.add(AveragePooling2D((1, 8)))\n",
        "model.add(dropoutType(dropoutRate))\n",
        "model.add(Flatten(name = 'flatten'))\n",
        "model.add(Dense(nb_classes, name = 'dense',kernel_constraint = max_norm(norm_rate)))\n",
        "model.add(Activation('softmax')) \n",
        "# eegnet = Model(outputs=Activation('softmax', name = 'softmax'))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Keras Implementation of EEGNet\\nhttp://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\\n\\nInputs:\\n    \\n  nb_classes      : int, number of classes to classify\\n  Chans, Samples  : number of channels and time points in the EEG data\\n  dropoutRate     : dropout fraction\\n  kernLength      : length of temporal convolution in first layer. We found\\n                    that setting this to be half the sampling rate worked\\n                    well in practice. For the SMR dataset in particular\\n                    since the data was high-passed at 4Hz we used a kernel\\n                    length of 32.     \\n  F1, F2          : number of temporal filters (F1) and number of pointwise\\n                    filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \\n  D               : number of spatial filters to learn within each temporal\\n                    convolution. Default: D = 2\\n  dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XTNqcn1zgxQ",
        "colab_type": "code",
        "outputId": "f71255b1-09ef-4d7c-8f5b-6b2ca5487748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])\n",
        "\n",
        "seqTrain=sequence.pad_sequences(sequences= X_train_trans, maxlen=maxlen, padding='post', dtype='float', truncating='post')\n",
        "seqTest=sequence.pad_sequences(sequences= X_test_trans, maxlen=maxlen, padding='post', dtype='float', truncating='post')\n",
        "\n",
        "seqTrain = seqTrain.reshape((-1, 1, maxlen, 1))\n",
        "seqTest = seqTest.reshape((-1, 1, maxlen, 1))\n",
        "# model.fit(seqTrain, y_train, batch_size = 256, validation_split=0.1, epochs = 100)\n",
        "model.fit(seqTrain, y_train_oneHot, epochs=10, batch_size=128, validation_data=(seqTest,y_test_oneHot))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 28651 samples, validate on 7162 samples\n",
            "Epoch 1/10\n",
            "28651/28651 [==============================] - 10s 345us/step - loss: 2.3113 - acc: 0.1014 - val_loss: 2.3025 - val_acc: 0.1025\n",
            "Epoch 2/10\n",
            "28651/28651 [==============================] - 3s 88us/step - loss: 2.3046 - acc: 0.0982 - val_loss: 2.3034 - val_acc: 0.0952\n",
            "Epoch 3/10\n",
            "28651/28651 [==============================] - 3s 89us/step - loss: 2.3038 - acc: 0.0992 - val_loss: 2.3027 - val_acc: 0.1033\n",
            "Epoch 4/10\n",
            "28651/28651 [==============================] - 3s 88us/step - loss: 2.3035 - acc: 0.1015 - val_loss: 2.3030 - val_acc: 0.1016\n",
            "Epoch 5/10\n",
            "28651/28651 [==============================] - 2s 86us/step - loss: 2.3031 - acc: 0.1037 - val_loss: 2.3032 - val_acc: 0.1026\n",
            "Epoch 6/10\n",
            "28651/28651 [==============================] - 3s 88us/step - loss: 2.3029 - acc: 0.1046 - val_loss: 2.3029 - val_acc: 0.1032\n",
            "Epoch 7/10\n",
            "28651/28651 [==============================] - 2s 85us/step - loss: 2.3031 - acc: 0.0998 - val_loss: 2.3029 - val_acc: 0.0919\n",
            "Epoch 8/10\n",
            "28651/28651 [==============================] - 3s 91us/step - loss: 2.3031 - acc: 0.1005 - val_loss: 2.3031 - val_acc: 0.0917\n",
            "Epoch 9/10\n",
            "28651/28651 [==============================] - 3s 89us/step - loss: 2.3030 - acc: 0.1006 - val_loss: 2.3032 - val_acc: 0.0956\n",
            "Epoch 10/10\n",
            "28651/28651 [==============================] - 2s 87us/step - loss: 2.3030 - acc: 0.1008 - val_loss: 2.3033 - val_acc: 0.0917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f134a219c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrtn4ULykv6c",
        "colab_type": "text"
      },
      "source": [
        "## Try LSTM and GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0z70vE16Hr",
        "colab_type": "text"
      },
      "source": [
        "### Stacked LSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suxIDMVH4xTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seqTrain=sequence.pad_sequences(sequences= X_train_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post')\n",
        "seqTest=sequence.pad_sequences(sequences= X_test_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post')\n",
        "\n",
        "seqTrain = seqTrain.reshape((-1, maxlen, 1))\n",
        "seqTest = seqTest.reshape((-1, maxlen, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KAEldqQzgxS",
        "colab_type": "code",
        "outputId": "6abbec9a-5bca-47ab-b193-e87df3d7935a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# https://www.analyticsvidhya.com/blog/2019/01/introduction-time-series-classification/\n",
        "# stateful-ness reference https://keras.io/getting-started/sequential-model-guide/\n",
        "## 29; len/29 is a whole number, it is needed... IDK why, but thats what the error message said \n",
        "\n",
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(256,batch_input_shape=(29, maxlen, 1),stateful=True, return_sequences=True)) # ,return_sequences=True is need for deep (\"stacked\")\n",
        "model.add(BatchNormalization())\n",
        "model.add(CuDNNLSTM(150, stateful=True, return_sequences=True)) # ,return_sequences=True is need for deep (\"stacked\")\n",
        "model.add(CuDNNLSTM(75,  stateful=True, return_sequences=False)) # ,return_sequences=True is need for deep (\"stacked\")\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32))\n",
        "model.add(ReLU())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (29, 50, 256)             265216    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (29, 50, 256)             1024      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (29, 50, 150)             244800    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (29, 75)                  68100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (29, 75)                  300       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (29, 32)                  2432      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (29, 32)                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (29, 10)                  330       \n",
            "=================================================================\n",
            "Total params: 582,202\n",
            "Trainable params: 581,540\n",
            "Non-trainable params: 662\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ-mVOgWaWgU",
        "colab_type": "code",
        "outputId": "dbfb8be8-13b9-4359-ea5b-a5aa14c3505f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "opt = keras.optimizers.RMSprop(lr=0.0001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.fit(seqTrain, y_train_oneHot, epochs=5, batch_size=29, validation_data=(seqTest,y_test_oneHot))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-dae9337deaca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oneHot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_oneHot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    827\u001b[0m                                  \u001b[0;34m'a number of samples that can be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                                  \u001b[0;34m'divided by the batch size. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                                  str(x[0].shape[0]) + ' samples')\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 28651 samples"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wECziwje8dvB",
        "colab_type": "text"
      },
      "source": [
        "###  Stacked GRU with Embedding\n",
        "\n",
        "* (Reference for Embedding](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfcdJESSfxYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seqTrain=sequence.pad_sequences(sequences= X_train_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post')\n",
        "seqTest=sequence.pad_sequences(sequences= X_test_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post')\n",
        "\n",
        "# seqTrain = seqTrain.reshape((-1, maxlen))\n",
        "# seqTest = seqTest.reshape((-1, maxlen))\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(seqTrain.shape[0], maxlen, input_length=maxlen))\n",
        "# input_length should be > maxLen? https://github.com/LuisPB7/fnc-msc/blob/master/fnc-model.py#L219\n",
        "\n",
        "model.add(CuDNNGRU(256,return_sequences=True)) # ,return_sequences=True is need for deep \n",
        "model.add(CuDNNGRU(128))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(ReLU())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy'])\n",
        "model.fit(seqTrain, y_train_oneHot, epochs=4, batch_size=128, validation_data=(seqTest,y_test_oneHot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbtZFVcs2zcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.evaluate(seqTest,y_test_oneHot)\n",
        "pred[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaH-aW_EzgxU",
        "colab_type": "text"
      },
      "source": [
        "### Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPAXDpnRzgxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seqTrain=sequence.pad_sequences(sequences= X_train_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post').reshape((-1, maxlen))\n",
        "seqTest=sequence.pad_sequences(sequences= X_test_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post').reshape((-1, maxlen))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(seqTrain.shape[0], maxlen, input_length=maxlen))\n",
        "model.add(Bidirectional(CuDNNLSTM(64,return_sequences=True)))\n",
        "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=False)))\n",
        "# same speed as CuDNNGRU()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(ReLU())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001)\n",
        "chk = ModelCheckpoint('best_model.pkl', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.fit(seqTrain, y_train_c, epochs=5, batch_size=64, callbacks=[chk], validation_data=(seqTest,y_test_c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4awcLaU_6jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seqTrain[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9UD7cFuzgxZ",
        "colab_type": "text"
      },
      "source": [
        "### 1D CNN + Bidirectional LSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIhdl5tqzgxc",
        "colab_type": "code",
        "outputId": "de534170-0161-4b58-8dac-f90cf4d7316a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "seqTrain=sequence.pad_sequences(sequences= X_train_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post').reshape((-1, maxlen))\n",
        "seqTest=sequence.pad_sequences(sequences= X_test_trans, maxlen=maxlen, padding='post', dtype='float32', truncating='post').reshape((-1, maxlen))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(seqTrain.shape[0], maxlen, input_length=maxlen))\n",
        "\n",
        "model.add(Conv1D(F1, kernLength, padding = 'same', use_bias= False)) # (1,Chans,Samples), use_bias= False))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "\n",
        "model.add(Conv1D(F1, kernLength, padding = 'same', use_bias= False)) # (1,Chans,Samples), use_bias= False))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "# model.add(Flatten())\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(64,return_sequences=True)))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=False)))\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "\n",
        "model.add(Dense(10, name = 'dense',kernel_constraint = max_norm(norm_rate),activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001)\n",
        "chk = ModelCheckpoint('best_model.pkl', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.fit(seqTrain, y_train_c, epochs=20, batch_size=64, callbacks=[chk], validation_data=(seqTest,y_test_c))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-bee557ab6ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer bidirectional_20: expected ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHV0Bzshzgxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "483ba20a-351c-4770-f62a-7d2e2b99a83d"
      },
      "source": [
        "model.predict(seqTest)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29786196, 0.04668574, 0.07827839, ..., 0.05150283, 0.07521413,\n",
              "        0.08752518],\n",
              "       [0.29786196, 0.04668574, 0.07827839, ..., 0.05150283, 0.07521413,\n",
              "        0.08752518],\n",
              "       [0.29786196, 0.04668574, 0.07827839, ..., 0.05150283, 0.07521413,\n",
              "        0.08752518],\n",
              "       ...,\n",
              "       [0.29786196, 0.04668574, 0.07827839, ..., 0.05150283, 0.07521413,\n",
              "        0.08752518],\n",
              "       [0.29786196, 0.04668574, 0.07827839, ..., 0.05150283, 0.07521413,\n",
              "        0.08752518],\n",
              "       [0.29786196, 0.04668574, 0.07827839, ..., 0.05150283, 0.07521413,\n",
              "        0.08752518]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E8WZmaHzgxf",
        "colab_type": "text"
      },
      "source": [
        "## ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy-F9y4Mzgxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOfQE_3Vzgxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1-mjJzdzgxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Eyxh6Izgxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fdn2chfzgxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqe0NXKmzgxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSDkhhiuzgxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTp7CpRazgxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjwiCHKIzgx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R_iOLmJzgx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Dd8B7gzgx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV3bT2rLzgyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KchBlyWzgyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haw359VTzgyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkBAN-xrzgyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csxw6vE1zgyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZBiQ8JTzgyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QhRYD5KzgyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAMSlIg3zgyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC1aHBDUzgyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MDwArZCzgyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_lzdnkRzgyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxpwxyTtzgyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5SnUHLPzgyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyBrPXiMzgyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqIxBpiKzgyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}