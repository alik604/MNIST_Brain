{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for common spatial pattern (CSP) feature calculation and classification for EEG data\n",
    "\n",
    "> Adapted from https://github.com/MultiScale-BCI/IV-2a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# import self defined functions\n",
    "from csp import generate_projection, generate_eye, extract_feature\n",
    "from filters import load_filterbank\n",
    "from get_data import get_data\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation = False\n",
    "\n",
    "data_path = 'data_2a_mat/'\n",
    "svm_kernel = 'linear'  # 'sigmoid'#'linear' # 'sigmoid', 'rbf', 'poly'\n",
    "svm_c = 0.1  # 0.05 for linear, 20 for rbf, poly: 0.1\n",
    "useCSP = True\n",
    "NO_splits = 5  # number of folds in cross validation\n",
    "fs = 250.  # sampling frequency\n",
    "NO_channels = 22  # number of EEG channels\n",
    "NO_subjects = 9\n",
    "NO_csp = 24  # Total number of CSP feature per band and timewindow\n",
    "bw = np.array([2, 4, 8, 16, 32])  # bandwidth of filtered signals\n",
    "ftype = 'butter'  # 'fir', 'butter'\n",
    "forder = 2  # 4\n",
    "filter_bank = load_filterbank(bw, fs, order=forder, max_freq=40,\n",
    "                                   ftype=ftype)  # get filterbank coeffs\n",
    "time_windows_flt = np.array([\n",
    "    [2.5, 3.5],\n",
    "    [3, 4],\n",
    "    [3.5, 4.5],\n",
    "    [4, 5],\n",
    "    [4.5, 5.5],\n",
    "    [5, 6],\n",
    "    [2.5, 4.5],\n",
    "    [3, 5],\n",
    "    [3.5, 5.5],\n",
    "    [4, 6],\n",
    "    [2.5, 6]]) * fs  # time windows in [s] x fs for using as a feature\n",
    "\n",
    "time_windows = time_windows_flt.astype(int)\n",
    "# restrict time windows and frequency bands\n",
    "# time_windows = time_windows[10] # use only largest timewindow\n",
    "# filter_bank = filter_bank[18:27] # use only 4Hz bands\n",
    "\n",
    "NO_bands = filter_bank.shape[0]\n",
    "NO_time_windows = int(time_windows.size / 2)\n",
    "NO_features = NO_csp * NO_bands * NO_time_windows\n",
    "train_time = 0\n",
    "train_trials = 0\n",
    "eval_time = 0\n",
    "eval_trials = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_csp():\n",
    "    ################################ Training ############################################################################\n",
    "    start_train = time.time()\n",
    "    # 1. Apply CSP to bands to get spatial filter\n",
    "    if useCSP:\n",
    "        w = generate_projection(train_data, train_label, NO_csp, filter_bank, time_windows)\n",
    "    else:\n",
    "        w = generate_eye(train_data, train_label, filter_bank, time_windows)\n",
    "\n",
    "    # 2. Extract features for training\n",
    "    feature_mat = extract_feature(train_data, w, filter_bank, time_windows)\n",
    "\n",
    "    # 3. Train SVM Model\n",
    "    if svm_kernel == 'linear':\n",
    "        clf = LinearSVC(C=svm_c, intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
    "                        penalty='l2', random_state=1, tol=0.00001)\n",
    "    else:\n",
    "        clf = SVC(svm_c, svm_kernel, degree=10, gamma='auto', coef0=0.0, tol=0.001, cache_size=10000,\n",
    "                  max_iter=-1, decision_function_shape='ovr')\n",
    "    clf.fit(feature_mat, train_label)\n",
    "\n",
    "    end_train = time.time()\n",
    "\n",
    "    global train_time\n",
    "    global train_trials\n",
    "    train_time += end_train - start_train\n",
    "    train_trials += len(train_label)\n",
    "\n",
    "    ################################# Evaluation ###################################################\n",
    "    start_eval = time.time()\n",
    "    eval_feature_mat = extract_feature(eval_data, w, filter_bank, time_windows)\n",
    "\n",
    "    success_rate = clf.score(eval_feature_mat, eval_label)\n",
    "\n",
    "    end_eval = time.time()\n",
    "\n",
    "    print(\"Time for one Evaluation \" + str((end_eval-start_eval)/len(eval_label)) )\n",
    "\n",
    "    global eval_time\n",
    "    global eval_trials\n",
    "    eval_time += end_eval - start_eval\n",
    "    eval_trials += len(eval_label)\n",
    "\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used features: 11352\n",
      "Test data set\n",
      "Subject1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kali\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for one Evaluation 0.12139537156264553\n",
      "0.8683274021352313\n",
      "Subject2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kali\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for one Evaluation 0.12081348348422101\n",
      "0.5724381625441696\n",
      "Subject3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kali\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for one Evaluation 0.11936283722901955\n",
      "0.8644688644688645\n",
      "Subject4:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3218b4ca2c6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0meval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0msuccess_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_csp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuccess_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-4a200d384e80>\u001b[0m in \u001b[0;36mrun_csp\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         clf = SVC(svm_c, svm_kernel, degree=10, gamma='auto', coef0=0.0, tol=0.001, cache_size=10000,\n\u001b[0;32m     19\u001b[0m                   max_iter=-1, decision_function_shape='ovr')\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mend_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kali\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kali\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Number of used features: \" + str(NO_features))\n",
    "\n",
    "# success rate sum over all subjects\n",
    "success_tot_sum = 0\n",
    "\n",
    "print(\"Test data set\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Go through all subjects\n",
    "for subject in range(1, NO_subjects + 1):\n",
    "\n",
    "    print(\"Subject\" + str(subject)+\":\")\n",
    "\n",
    "\n",
    "    # load Eval data\n",
    "    train_data, train_label = get_data(subject, True, data_path)\n",
    "    eval_data, eval_label = get_data(subject, False, data_path)\n",
    "    success_rate = run_csp()\n",
    "\n",
    "    print(success_rate)\n",
    "    success_tot_sum += success_rate\n",
    "\n",
    "# Average success rate over all subjects\n",
    "print(\"Average success rate: \" + str(success_tot_sum / NO_subjects))\n",
    "\n",
    "print(\"Training average time: \" + str(train_time / NO_subjects))\n",
    "print(\"Evaluation average time: \" + str(eval_time / NO_subjects))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time elapsed [s] \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
